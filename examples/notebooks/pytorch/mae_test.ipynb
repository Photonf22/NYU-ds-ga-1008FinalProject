{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0",
      "metadata": {
        "id": "0"
      },
      "source": [
        "This example requires the following dependencies to be installed:\n",
        "pip install lightly[timm]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rS-dY-5jnG8T"
      },
      "id": "rS-dY-5jnG8T"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1",
        "outputId": "41785eef-ea67-4b54-be13-94592c429b98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lightly[timm]\n",
            "  Downloading lightly-1.5.22-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from lightly[timm]) (2025.11.12)\n",
            "Collecting hydra-core>=1.0.0 (from lightly[timm])\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting lightly_utils~=0.0.0 (from lightly[timm])\n",
            "  Downloading lightly_utils-0.0.2-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.12/dist-packages (from lightly[timm]) (2.0.2)\n",
            "Requirement already satisfied: python_dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from lightly[timm]) (2.9.0.post0)\n",
            "Requirement already satisfied: requests>=2.27.0 in /usr/local/lib/python3.12/dist-packages (from lightly[timm]) (2.32.4)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from lightly[timm]) (1.17.0)\n",
            "Requirement already satisfied: tqdm>=4.44 in /usr/local/lib/python3.12/dist-packages (from lightly[timm]) (4.67.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from lightly[timm]) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from lightly[timm]) (0.24.0+cu126)\n",
            "Requirement already satisfied: pydantic>=1.10.5 in /usr/local/lib/python3.12/dist-packages (from lightly[timm]) (2.12.3)\n",
            "Collecting pytorch_lightning>=1.0.4 (from lightly[timm])\n",
            "  Downloading pytorch_lightning-2.6.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: urllib3>=1.25.3 in /usr/local/lib/python3.12/dist-packages (from lightly[timm]) (2.5.0)\n",
            "Collecting aenum>=3.1.11 (from lightly[timm])\n",
            "  Downloading aenum-3.1.16-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: timm>=0.9.9 in /usr/local/lib/python3.12/dist-packages (from lightly[timm]) (1.0.22)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.12/dist-packages (from hydra-core>=1.0.0->lightly[timm]) (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from hydra-core>=1.0.0->lightly[timm]) (4.9.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from hydra-core>=1.0.0->lightly[timm]) (25.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from lightly_utils~=0.0.0->lightly[timm]) (11.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.10.5->lightly[timm]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.10.5->lightly[timm]) (2.41.4)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.10.5->lightly[timm]) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.10.5->lightly[timm]) (0.4.2)\n",
            "Requirement already satisfied: PyYAML>5.4 in /usr/local/lib/python3.12/dist-packages (from pytorch_lightning>=1.0.4->lightly[timm]) (6.0.3)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly[timm]) (2025.3.0)\n",
            "Collecting torchmetrics>0.7.0 (from pytorch_lightning>=1.0.4->lightly[timm])\n",
            "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting lightning-utilities>=0.10.0 (from pytorch_lightning>=1.0.4->lightly[timm])\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.27.0->lightly[timm]) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.27.0->lightly[timm]) (3.11)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from timm>=0.9.9->lightly[timm]) (0.36.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from timm>=0.9.9->lightly[timm]) (0.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->lightly[timm]) (3.20.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->lightly[timm]) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->lightly[timm]) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->lightly[timm]) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->lightly[timm]) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->lightly[timm]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->lightly[timm]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->lightly[timm]) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->lightly[timm]) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->lightly[timm]) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->lightly[timm]) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->lightly[timm]) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->lightly[timm]) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->lightly[timm]) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->lightly[timm]) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->lightly[timm]) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->lightly[timm]) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->lightly[timm]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->lightly[timm]) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->lightly[timm]) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->lightly[timm]) (3.5.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly[timm]) (3.13.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->lightly[timm]) (1.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm>=0.9.9->lightly[timm]) (1.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->lightly[timm]) (3.0.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly[timm]) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly[timm]) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly[timm]) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly[timm]) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly[timm]) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly[timm]) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly[timm]) (1.22.0)\n",
            "Downloading aenum-3.1.16-py3-none-any.whl (165 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.6/165.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightly_utils-0.0.2-py3-none-any.whl (6.4 kB)\n",
            "Downloading pytorch_lightning-2.6.0-py3-none-any.whl (849 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.5/849.5 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightly-1.5.22-py3-none-any.whl (859 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m859.3/859.3 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Downloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: aenum, lightning-utilities, lightly_utils, hydra-core, torchmetrics, pytorch_lightning, lightly\n",
            "Successfully installed aenum-3.1.16 hydra-core-1.3.2 lightly-1.5.22 lightly_utils-0.0.2 lightning-utilities-0.15.2 pytorch_lightning-2.6.0 torchmetrics-1.8.2\n"
          ]
        }
      ],
      "source": [
        "!pip install lightly[timm]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2",
      "metadata": {
        "id": "2"
      },
      "outputs": [],
      "source": [
        "# Note: The model and training settings do not follow the reference settings\n",
        "# from the paper. The settings are chosen such that the example can easily be\n",
        "# run on a small dataset with a single GPU.\n",
        "import torch\n",
        "import torchvision\n",
        "from timm.models.vision_transformer import vit_base_patch32_224\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3",
      "metadata": {
        "id": "3"
      },
      "outputs": [],
      "source": [
        "from lightly.models import utils\n",
        "from lightly.models.modules import MAEDecoderTIMM, MaskedVisionTransformerTIMM\n",
        "from lightly.transforms import MAETransform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4",
      "metadata": {
        "id": "4"
      },
      "outputs": [],
      "source": [
        "class MAE(nn.Module):\n",
        "    def __init__(self, vit):\n",
        "        super().__init__()\n",
        "\n",
        "        decoder_dim = 512\n",
        "        self.mask_ratio = 0.75\n",
        "        self.patch_size = vit.patch_embed.patch_size[0]\n",
        "\n",
        "        self.backbone = MaskedVisionTransformerTIMM(vit=vit)\n",
        "        self.sequence_length = self.backbone.sequence_length\n",
        "        self.decoder = MAEDecoderTIMM(\n",
        "            num_patches=vit.patch_embed.num_patches,\n",
        "            patch_size=self.patch_size,\n",
        "            embed_dim=vit.embed_dim,\n",
        "            decoder_embed_dim=decoder_dim,\n",
        "            decoder_depth=1,\n",
        "            decoder_num_heads=16,\n",
        "            mlp_ratio=4.0,\n",
        "            proj_drop_rate=0.0,\n",
        "            attn_drop_rate=0.0,\n",
        "        )\n",
        "\n",
        "    def forward_encoder(self, images, idx_keep=None):\n",
        "        return self.backbone.encode(images=images, idx_keep=idx_keep)\n",
        "\n",
        "    def forward_decoder(self, x_encoded, idx_keep, idx_mask):\n",
        "        # build decoder input\n",
        "        batch_size = x_encoded.shape[0]\n",
        "        x_decode = self.decoder.embed(x_encoded)\n",
        "        x_masked = utils.repeat_token(\n",
        "            self.decoder.mask_token, (batch_size, self.sequence_length)\n",
        "        )\n",
        "        x_masked = utils.set_at_index(x_masked, idx_keep, x_decode.type_as(x_masked))\n",
        "\n",
        "        # decoder forward pass\n",
        "        x_decoded = self.decoder.decode(x_masked)\n",
        "\n",
        "        # predict pixel values for masked tokens\n",
        "        x_pred = utils.get_at_index(x_decoded, idx_mask)\n",
        "        x_pred = self.decoder.predict(x_pred)\n",
        "        return x_pred\n",
        "\n",
        "    def forward(self, images):\n",
        "        batch_size = images.shape[0]\n",
        "        idx_keep, idx_mask = utils.random_token_mask(\n",
        "            size=(batch_size, self.sequence_length),\n",
        "            mask_ratio=self.mask_ratio,\n",
        "            device=images.device,\n",
        "        )\n",
        "        x_encoded = self.forward_encoder(images=images, idx_keep=idx_keep)\n",
        "        x_pred = self.forward_decoder(\n",
        "            x_encoded=x_encoded, idx_keep=idx_keep, idx_mask=idx_mask\n",
        "        )\n",
        "\n",
        "        # get image patches for masked tokens\n",
        "        patches = utils.patchify(images, self.patch_size)\n",
        "        # must adjust idx_mask for missing class token\n",
        "        target = utils.get_at_index(patches, idx_mask - 1)\n",
        "        return x_pred, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5",
      "metadata": {
        "id": "5"
      },
      "outputs": [],
      "source": [
        "vit = vit_base_patch32_224()\n",
        "model = MAE(vit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6",
      "metadata": {
        "id": "6"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "7"
      },
      "outputs": [],
      "source": [
        "transform = MAETransform()\n",
        "# we ignore object detection annotations by setting target_transform to return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8",
      "metadata": {
        "id": "8"
      },
      "outputs": [],
      "source": [
        "def target_transform(t):\n",
        "    return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9",
      "metadata": {
        "id": "9"
      },
      "outputs": [],
      "source": [
        "dataset = torchvision.datasets.VOCDetection(\n",
        "    \"datasets/pascal_voc\",\n",
        "    download=True,\n",
        "    transform=transform,\n",
        "    target_transform=target_transform,\n",
        ")\n",
        "# or create a dataset from a folder containing images or videos:\n",
        "# dataset = LightlyDataset(\"path/to/folder\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10",
      "metadata": {
        "id": "10"
      },
      "outputs": [],
      "source": [
        "dataloader = torch.utils.data.DataLoader(\n",
        "    dataset,\n",
        "    batch_size=256,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    num_workers=8,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11",
      "metadata": {
        "id": "11"
      },
      "outputs": [],
      "source": [
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1.5e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12",
      "metadata": {
        "id": "12"
      },
      "outputs": [],
      "source": [
        "print(\"Starting Training\")\n",
        "for epoch in range(10):\n",
        "    total_loss = 0\n",
        "    for batch in dataloader:\n",
        "        views = batch[0]\n",
        "        images = views[0].to(device)  # views contains only a single view\n",
        "        predictions, targets = model(images)\n",
        "        loss = criterion(predictions, targets)\n",
        "        total_loss += loss.detach()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    print(f\"epoch: {epoch:>02}, loss: {avg_loss:.5f}\")"
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}