{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "id": "0"
   },
   "source": [
    "This example requires the following dependencies to be installed:\n",
    "pip install lightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "id": "1"
   },
   "outputs": [],
   "source": [
    "# !pip install lightly\n",
    "!export CUDA_VISIBLE_DEVICES=3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {
    "id": "2"
   },
   "source": [
    "Note: The model and training settings do not follow the reference settings\n",
    "from the paper. The settings are chosen such that the example can easily be\n",
    "run on a small dataset with a single GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "id": "3"
   },
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "id": "4"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "id": "5"
   },
   "outputs": [],
   "source": [
    "from lightly.loss import DINOLoss\n",
    "from lightly.models.modules import DINOProjectionHead\n",
    "from lightly.models.utils import deactivate_requires_grad, update_momentum\n",
    "from lightly.transforms.dino_transform import DINOTransform\n",
    "from lightly.utils.scheduler import cosine_schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bJWwZr0Q6oLu",
   "metadata": {
    "id": "bJWwZr0Q6oLu"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "\n",
    "class RawImageDataset(Dataset):\n",
    "    \"\"\"Dataset that loads images directly from raw files.\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, transform=None, image_extensions=None):\n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.transform = transform\n",
    "\n",
    "        if image_extensions is None:\n",
    "            image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.JPEG', '*.JPG', '*.PNG']\n",
    "\n",
    "        # Find all image files\n",
    "        self.image_paths = []\n",
    "        print(f\"Searching for images in: {self.root_dir}\")\n",
    "\n",
    "        for pattern in image_extensions:\n",
    "            found = glob.glob(str(self.root_dir / '**' / pattern), recursive=True)\n",
    "            self.image_paths.extend(found)\n",
    "            if found:\n",
    "                print(f\"  Found {len(found)} {pattern} files\")\n",
    "\n",
    "        self.image_paths.sort()\n",
    "        print(f\"Total images found: {len(self.image_paths)}\")\n",
    "\n",
    "        if len(self.image_paths) == 0:\n",
    "            print(\"\\nWarning: No images found. Directory structure (first 20 items):\")\n",
    "            for item in sorted(self.root_dir.rglob('*'))[:20]:\n",
    "                print(f\"  {item}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # import pdb\n",
    "        # pdb.set_trace()\n",
    "        img_path = self.image_paths[idx]\n",
    "\n",
    "        try:\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {img_path}: {e}\")\n",
    "            img = Image.new('RGB', (96, 96), color='black')\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "            # import pdb; pdb.set_trace()\n",
    "            # print(img.shape,\"old image shape\")\n",
    "            # img = img[0]\n",
    "            # print(img.shape,\"new image shape\")\n",
    "\n",
    "        return img\n",
    "\n",
    "\n",
    "def download_and_extract_dataset(repo_id, cache_dir=None, max_workers=4):\n",
    "    \"\"\"Download and extract dataset from HuggingFace.\"\"\"\n",
    "\n",
    "    print(f\"Downloading dataset from {repo_id}...\")\n",
    "\n",
    "    try:\n",
    "        local_dir = snapshot_download(\n",
    "            repo_id=repo_id,\n",
    "            repo_type=\"dataset\",\n",
    "            cache_dir=cache_dir,\n",
    "            max_workers=max_workers,\n",
    "            resume_download=True,\n",
    "        )\n",
    "        print(f\"Dataset downloaded to: {local_dir}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during download: {e}\")\n",
    "        print(\"Retrying with single worker...\")\n",
    "        local_dir = snapshot_download(\n",
    "            repo_id=repo_id,\n",
    "            repo_type=\"dataset\",\n",
    "            cache_dir=cache_dir,\n",
    "            max_workers=1,\n",
    "            resume_download=True,\n",
    "        )\n",
    "        print(f\"Dataset downloaded to: {local_dir}\")\n",
    "\n",
    "    # Extract zip files if present\n",
    "    local_path = Path(local_dir)\n",
    "    zip_files = list(local_path.glob('*.zip'))\n",
    "\n",
    "    if zip_files:\n",
    "        print(f\"\\nFound {len(zip_files)} zip files. Extracting...\")\n",
    "        extract_dir = local_path / 'extracted'\n",
    "        extract_dir.mkdir(exist_ok=True)\n",
    "\n",
    "        # for zip_file in zip_files:\n",
    "        #     print(f\"  Extracting {zip_file.name}...\")\n",
    "        #     try:\n",
    "        #         with zipfile.ZipFile(zip_file, 'r') as zf:\n",
    "        #             zf.extractall(extract_dir)\n",
    "        #         print(\"    ✓ Extracted successfully\")\n",
    "        #     except Exception as e:\n",
    "        #         print(f\"    ✗ Error: {e}\")\n",
    "\n",
    "        return extract_dir\n",
    "    else:\n",
    "        print(\"No zip files found, using directory as-is\")\n",
    "        return local_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SHbyXBSR64na",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260,
     "referenced_widgets": [
      "9cfd55e334fc4943b4674f3ba8502249",
      "f5ac001d79c84bc697ca2180371a8587",
      "5cc70c49ab194fb2a3891387b414ae69",
      "4bbed79e5c47409b92cf09d5d440034e",
      "18901c5c91c64449ab3a656ca98da3ab",
      "953a58a23a7c49a7a196c85d31bfc3de",
      "b7784a2864f548a585841176447886c4",
      "048804520ca544ea9580b6e1752033e7",
      "88a7c0f2334e4b7c859eab2ec0a6b364",
      "93c81c0b7064417186bd7dc336b37318",
      "866161d5edc9424f8144f6316f49bc47"
     ]
    },
    "id": "SHbyXBSR64na",
    "outputId": "ebbe8354-fcc9-41f1-d651-6c42d3633d70"
   },
   "outputs": [],
   "source": [
    "# Download and extract dataset\n",
    "# data_dir = download_and_extract_dataset(\n",
    "#     repo_id=\"tsbpp/fall2025_deeplearning\",\n",
    "#     cache_dir=None,\n",
    "#     max_workers=4\n",
    "# )\n",
    "data_dir = Path('./data/devel')\n",
    "# Create transform\n",
    "transform = DINOTransform()\n",
    "# transform = get_mae_transform()\n",
    "\n",
    "# Create dataset\n",
    "dataset = RawImageDataset(data_dir, transform=transform)\n",
    "print(f\"\\nDataset ready with {len(dataset)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "id": "6"
   },
   "outputs": [],
   "source": [
    "class DINO(torch.nn.Module):\n",
    "    def __init__(self, backbone, input_dim):\n",
    "        super().__init__()\n",
    "        self.student_backbone = backbone\n",
    "        self.student_head = DINOProjectionHead(\n",
    "            input_dim, 512, 64, 2048, freeze_last_layer=30\n",
    "        )\n",
    "        self.teacher_backbone = copy.deepcopy(backbone)\n",
    "        self.teacher_head = DINOProjectionHead(input_dim, 512, 64, 2048)\n",
    "        deactivate_requires_grad(self.teacher_backbone)\n",
    "        deactivate_requires_grad(self.teacher_head)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.student_backbone(x).flatten(start_dim=1)\n",
    "        z = self.student_head(y)\n",
    "        return z\n",
    "\n",
    "    def forward_teacher(self, x):\n",
    "        y = self.teacher_backbone(x).flatten(start_dim=1)\n",
    "        z = self.teacher_head(y)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "id": "7"
   },
   "outputs": [],
   "source": [
    "resnet = torchvision.models.resnet34()\n",
    "backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
    "input_dim = 512\n",
    "# instead of a resnet you can also use a vision transformer backbone as in the\n",
    "# original paper (you might have to reduce the batch size in this case):\n",
    "# backbone = torch.hub.load('facebookresearch/dino:main', 'dino_vits16', pretrained=False)\n",
    "# input_dim = backbone.embed_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8",
    "outputId": "01205f27-6085-4d04-911c-7861f5db6c8d"
   },
   "outputs": [],
   "source": [
    "model = DINO(backbone, input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9",
    "outputId": "d3e9da54-b794-4ddf-b90f-257c0be23215"
   },
   "outputs": [],
   "source": [
    "device = \"cuda:3\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f86926-ccac-40ca-9d5e-38a632ee3897",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Using device:\", device)\n",
    "if device == \"cuda\":\n",
    "    print(\"Current device index:\", torch.cuda.current_device())\n",
    "    print(\"Device name:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HS3dE7eSDZMn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HS3dE7eSDZMn",
    "outputId": "d6f71511-7cdc-400a-abc9-88cdd6e40624"
   },
   "outputs": [],
   "source": [
    "def count_params(module):\n",
    "    return sum(p.numel() for p in module.parameters())\n",
    "\n",
    "total_params = count_params(model)\n",
    "student_backbone_params = count_params(model.student_backbone)\n",
    "student_head_params = count_params(model.student_head)\n",
    "teacher_backbone_params = count_params(model.teacher_backbone)\n",
    "teacher_head_params = count_params(model.teacher_head)\n",
    "\n",
    "student_total = student_backbone_params + student_head_params\n",
    "teacher_total = teacher_backbone_params + teacher_head_params\n",
    "\n",
    "print(f\"Total params (student + teacher + heads): {total_params:,}\")\n",
    "print(f\"  Student backbone: {student_backbone_params:,}\")\n",
    "print(f\"  Student head:     {student_head_params:,}\")\n",
    "print(f\"  Student TOTAL:    {student_total:,}\")\n",
    "print(f\"  Teacher backbone: {teacher_backbone_params:,}\")\n",
    "print(f\"  Teacher head:     {teacher_head_params:,}\")\n",
    "print(f\"  Teacher TOTAL:    {teacher_total:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "id": "10"
   },
   "outputs": [],
   "source": [
    "transform = DINOTransform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "id": "11"
   },
   "outputs": [],
   "source": [
    "# we ignore object detection annotations by setting target_transform to return 0\n",
    "def target_transform(t):\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "id": "12"
   },
   "outputs": [],
   "source": [
    "# dataset = torchvision.datasets.VOCDetection(\n",
    "#     \"datasets/pascal_voc\",\n",
    "#     download=True,\n",
    "#     transform=transform,\n",
    "#     target_transform=target_transform,\n",
    "# )\n",
    "\n",
    "# or create a dataset from a folder containing images or videos:\n",
    "# dataset = LightlyDataset(\"path/to/folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "id": "13"
   },
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "id": "14"
   },
   "outputs": [],
   "source": [
    "# criterion = DINOLoss(\n",
    "#     output_dim=2048,\n",
    "#     warmup_teacher_temp_epochs=5,\n",
    "# )\n",
    "# # move loss to correct device because it also contains parameters\n",
    "# criterion = criterion.to(device)\n",
    "criterion = DINOLoss(\n",
    "    output_dim=2048,\n",
    "    warmup_teacher_temp=0.08,          # start higher\n",
    "    teacher_temp=0.04,                 # end not too sharp\n",
    "    warmup_teacher_temp_epochs=10,     # warm up longer\n",
    "    student_temp=0.1,\n",
    "    center_momentum=0.9,               # keep default-ish EMA on center\n",
    ").to(device)\n",
    "\n",
    "global_batch_size = 256\n",
    "base_lr0 = 5e-4\n",
    "base_lr = base_lr0 * (global_batch_size / 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "id": "15"
   },
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=3e-4, #TODO: update to use base_lr\n",
    "    weight_decay=1e-4,\n",
    "    betas=(0.9, 0.95),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a810d68-b9c3-49ba-a653-1d724bb9bfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup_epochs = 10\n",
    "min_lr = 1e-6\n",
    "\n",
    "def cosine_lr(epoch):\n",
    "    if epoch < warmup_epochs:\n",
    "        return (epoch + 1) / warmup_epochs\n",
    "    t = (epoch - warmup_epochs) / max(1, (epochs - warmup_epochs))\n",
    "    return min_lr / base_lr + 0.5 * (1 + math.cos(math.pi * t)) * (1 - min_lr / base_lr)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, cosine_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7bc79c-c04b-4491-9aca-b0efa6c2233d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def teacher_entropy(logits):\n",
    "    # logits: (B, C)\n",
    "    probs = torch.softmax(logits, dim=-1)\n",
    "    return -(probs * (probs + 1e-8).log()).sum(dim=-1).mean()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "id": "16"
   },
   "outputs": [],
   "source": [
    "epochs = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OqQ4dQQ4AcC_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OqQ4dQQ4AcC_",
    "outputId": "c79e25a4-4c5d-4b41-98dc-d6663316d91d"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "import wandb\n",
    "\n",
    "# ---------- Drive setup ----------\n",
    "# try:\n",
    "#     from google.colab import drive\n",
    "#     drive.mount('/content/drive')\n",
    "#     DRIVE_ROOT = Path(\"/content/drive/MyDrive\")\n",
    "#     IS_COLAB = True\n",
    "#     print(\"✓ Running on Colab, Drive mounted.\")\n",
    "# except Exception:\n",
    "#     DRIVE_ROOT = Path(\"./saved_models\")\n",
    "#     IS_COLAB = False\n",
    "#     print(\"⚠️ Not on Colab, using local folder ./saved_models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "17",
    "outputId": "c3ca42c8-834a-414e-b64a-f0048b3f0af6"
   },
   "outputs": [],
   "source": [
    "# ---------- wandb init ----------\n",
    "# ---------- Project / save dir ----------\n",
    "PROJECT_NAME = \"dino-v1\"  # wandb project AND folder name\n",
    "DRIVE_ROOT = \"outputs\"\n",
    "save_dir = Path(DRIVE_ROOT) / Path(PROJECT_NAME)\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "wandb.init(\n",
    "    entity=\"lquan9\",\n",
    "    project=PROJECT_NAME,\n",
    "    name=\"dino-resnet34-run-1\",      # change run name if you like\n",
    ")\n",
    "\n",
    "print(\"Starting Training\")\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "global_step = 0\n",
    "step_start = time.time()\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    momentum_val = cosine_schedule(epoch, epochs, 0.996, 1)\n",
    "\n",
    "    for views in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\"):   # views is that list you just inspected\n",
    "        # EMA update for teacher\n",
    "        update_momentum(model.student_backbone, model.teacher_backbone, m=momentum_val)\n",
    "        update_momentum(model.student_head, model.teacher_head, m=momentum_val)\n",
    "\n",
    "        # move all crops to GPU\n",
    "        views = [v.to(device) for v in views]\n",
    "\n",
    "        # first two are global crops for the teacher\n",
    "        global_views = views[:2]\n",
    "\n",
    "        # teacher only on global crops\n",
    "        teacher_out = [model.forward_teacher(v) for v in global_views]\n",
    "\n",
    "        # Inside training loop, after computing teacher_out\n",
    "        with torch.no_grad():\n",
    "        # teacher_out is a list of tensors for the two global crops, same shape\n",
    "            t_logits = teacher_out[0]  # (B, 2048)\n",
    "            ent = teacher_entropy(t_logits)\n",
    "            if global_step % 100 == 0:\n",
    "                wandb.log({\"teacher_entropy\": ent.item(), \"step\": global_step})\n",
    "\n",
    "        # student on all crops (global + local)\n",
    "        student_out = [model.forward(v) for v in views]\n",
    "\n",
    "        loss = criterion(teacher_out, student_out, epoch=epoch)\n",
    "        total_loss += loss.detach()\n",
    "\n",
    "        # optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # freeze_epochs = 30  # instead of relying on default 1 epoch\n",
    "        \n",
    "        model.student_head.cancel_last_layer_gradients(current_epoch=epoch)\n",
    "        \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    #scheduler.step() # TODO: add scheduler\n",
    "        # ---- wandb STEP LOGGING ----\n",
    "        wandb.log(\n",
    "            {\n",
    "                \"loss/step\": loss.item(),\n",
    "                \"time/step_sec\": time.time() - step_start,\n",
    "                \"step\": global_step,\n",
    "                \"epoch\": epoch,\n",
    "            },\n",
    "            step=global_step,\n",
    "        )\n",
    "\n",
    "        global_step += 1\n",
    "        step_start = time.time()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f\"epoch: {epoch:>02}, loss: {avg_loss:.5f}\")\n",
    "\n",
    "    # ---- wandb logging ----\n",
    "    wandb.log({\n",
    "        \"loss/train\": avg_loss,\n",
    "        \"epoch\": epoch,\n",
    "    })\n",
    "\n",
    "    # ---- Save checkpoint to Drive (always same filename) ----\n",
    "    ckpt_path = save_dir / f\"{PROJECT_NAME}_latest.pt\"\n",
    "    torch.save(\n",
    "        {\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state\": model.state_dict(),\n",
    "            \"optimizer_state\": optimizer.state_dict(),\n",
    "            \"avg_loss\": avg_loss,\n",
    "        },\n",
    "        ckpt_path,\n",
    "    )\n",
    "    print(f\"✓ Saved checkpoint: {ckpt_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cu5UWVs_RqX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4cu5UWVs_RqX",
    "outputId": "ec407eed-ad7b-4c8c-af37-92ca36690f6c"
   },
   "outputs": [],
   "source": [
    "views = next(iter(dataloader))\n",
    "print(type(views), len(views))\n",
    "for i, v in enumerate(views):\n",
    "    print(i, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jKmkTErc_c3S",
   "metadata": {
    "id": "jKmkTErc_c3S"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "048804520ca544ea9580b6e1752033e7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "18901c5c91c64449ab3a656ca98da3ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4bbed79e5c47409b92cf09d5d440034e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_93c81c0b7064417186bd7dc336b37318",
      "placeholder": "​",
      "style": "IPY_MODEL_866161d5edc9424f8144f6316f49bc47",
      "value": " 6/6 [00:00&lt;00:00, 675.90it/s]"
     }
    },
    "5cc70c49ab194fb2a3891387b414ae69": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_048804520ca544ea9580b6e1752033e7",
      "max": 6,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_88a7c0f2334e4b7c859eab2ec0a6b364",
      "value": 6
     }
    },
    "866161d5edc9424f8144f6316f49bc47": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "88a7c0f2334e4b7c859eab2ec0a6b364": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "93c81c0b7064417186bd7dc336b37318": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "953a58a23a7c49a7a196c85d31bfc3de": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9cfd55e334fc4943b4674f3ba8502249": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f5ac001d79c84bc697ca2180371a8587",
       "IPY_MODEL_5cc70c49ab194fb2a3891387b414ae69",
       "IPY_MODEL_4bbed79e5c47409b92cf09d5d440034e"
      ],
      "layout": "IPY_MODEL_18901c5c91c64449ab3a656ca98da3ab"
     }
    },
    "b7784a2864f548a585841176447886c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f5ac001d79c84bc697ca2180371a8587": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_953a58a23a7c49a7a196c85d31bfc3de",
      "placeholder": "​",
      "style": "IPY_MODEL_b7784a2864f548a585841176447886c4",
      "value": "Fetching 6 files: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
