{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc761ad1",
   "metadata": {},
   "source": [
    "# Example based on our README.md\n",
    "1. Dataset download\n",
    "2. Pre-training\n",
    "3. Fine-tuning\n",
    "4. Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9de0bef",
   "metadata": {},
   "source": [
    "\n",
    "### 1. Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1e8ab29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cc3m_96px_part1.zip: 100%|███████████████████| 521M/521M [00:05<00:00, 98.3MB/s]\n",
      "cc3m_96px_part2.zip: 100%|███████████████████| 521M/521M [00:05<00:00, 97.2MB/s]\n",
      "cc3m_96px_part3.zip: 100%|███████████████████| 520M/520M [00:06<00:00, 82.5MB/s]\n",
      "cc3m_96px_part4.zip: 100%|███████████████████| 521M/521M [00:05<00:00, 96.5MB/s]\n",
      "cc3m_96px_part5.zip: 100%|███████████████████| 521M/521M [00:05<00:00, 98.7MB/s]\n",
      "Generating train split: 500000 examples [00:26, 19077.97 examples/s]\n",
      "Split 'train' available under /home/long/code/dl_project1/experiments/data\n"
     ]
    }
   ],
   "source": [
    "# using the cli\n",
    "!python -m wejepa.datasets.download --dataset-root ./data --dataset-name tsbpp/fall2025_deeplearning --splits train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21635921",
   "metadata": {},
   "source": [
    "### 2. Pre-training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e90f233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the cli\n",
    "\n",
    "# print the config\n",
    "!python -m wejepa.train.pretrain --config hf_config.json --print-config\n",
    "\n",
    "# pretrain the model\n",
    "!python -m wejepa.train.pretrain --config hf_config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52b311f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# programmatically\n",
    "from wejepa import default_config, launch_pretraining\n",
    "cfg = default_config()\n",
    "launch_pretraining(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffda647",
   "metadata": {},
   "source": [
    "### 3. Fine tuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2913c702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the cli\n",
    "!python -m wejepa.train.finetune \\\n",
    "    --checkpoint outputs/ijepa/ijepa_epoch_0005.pt \\\n",
    "    --epochs 10 \\\n",
    "    --batch-size 256 \\\n",
    "    --lr 3e-4 \\\n",
    "    --num-classes 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f283f657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# programmatically\n",
    "from wejepa.train import FinetuneConfig, train_linear_probe\n",
    "\n",
    "ft_cfg = FinetuneConfig(\n",
    "    checkpoint_path=\"outputs/ijepa/ijepa_epoch_0005.pt\",\n",
    "    epochs=5,\n",
    "    batch_size=128,\n",
    "    learning_rate=1e-3,\n",
    ")\n",
    "train_linear_probe(ft_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4317f0",
   "metadata": {},
   "source": [
    "### 4. Running Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f0b938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from datasets import load_dataset\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "from wejepa.train import load_backbone_from_checkpoint\n",
    "from wejepa import default_config\n",
    "\n",
    "cfg = default_config()\n",
    "backbone = load_backbone_from_checkpoint(\"outputs/ijepa/ijepa_epoch_0005.pt\", cfg)\n",
    "backbone.eval()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(cfg.data.image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(cfg.data.normalization_mean, cfg.data.normalization_std),\n",
    "])\n",
    "\n",
    "ds = load_dataset(\n",
    "    \"./data/tsbpp___fall2025_deeplearning\",\n",
    "    split=\"train\",\n",
    ")\n",
    "\n",
    "label_feature = ds.features[\"label\"] if hasattr(ds, \"features\") else None\n",
    "label_names = label_feature.names if label_feature is not None else None\n",
    "num_classes = len(label_names) if label_names is not None else 100 # default to 100 classes\n",
    "\n",
    "decoder = LinearProbe(backbone, num_classes)\n",
    "decoder.load_state_dict(torch.load(\"outputs/ijepa/linear_probe.pt\", map_location=\"cpu\"))\n",
    "decoder.eval()\n",
    "\n",
    "# grab an image from the dataset\n",
    "image = transform(ds[0][\"image\"]).unsqueeze(0)\n",
    "print(f\"Image shape: {image.shape}\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = decoder(image)\n",
    "    probs = torch.softmax(logits,dim=1)\n",
    "    pred_ind = int(probs.argmax(dim=1).item())\n",
    "\n",
    "pred_label = label_names[pred_ind] if label_names is not None else str(pred_ind)\n",
    "top5_inds = probs.topk(5).indices.squeeze(0).tolist()\n",
    "top5_labels = [label_names[i] if label_names is not None else str(i) for i in top5_inds]\n",
    "print(f\"Predicted label: {pred_label}\")\n",
    "print(f\"Top-5 predicted labels: {top5_labels}\")\n",
    "\n",
    "# remove batch dimension and convert to numpy\n",
    "img_np = image.squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
    "\n",
    "# undo normalization for display\n",
    "mean = np.array(cfg.data.normalization_mean)\n",
    "std = np.array(cfg.data.normalization_std)\n",
    "img_np = (img_np * std) + mean\n",
    "img_np = np.clip(img_np, 0, 1)\n",
    "\n",
    "plt.imshow(img_np)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "with torch.no_grad():\n",
    "    tokens = backbone(image)\n",
    "    pooled = tokens.mean(dim=1)  # embeddings for downstream heads\n",
    "\n",
    "# TODO: use the embeddings `pooled` for downstream tasks like classification \n",
    "print(f\"Extracted embeddings shape: {pooled.shape}\")\n",
    "\n",
    "num_classes = 100  # adjust based on your dataset\n",
    "classifier = torch.nn.Linear(pooled.size(1), num_classes)\n",
    "logits = classifier(pooled)\n",
    "print(f\"Logits shape: {logits.shape}\")\n",
    "\n",
    "# display the classified scores\n",
    "print(f\"Classified scores: {logits}\")\n",
    "\n",
    "# assign predicted class\n",
    "predicted_class = torch.argmax(logits, dim=1)\n",
    "print(f\"Predicted class: {predicted_class.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81e75d3",
   "metadata": {},
   "source": [
    "### 5. Different Backbones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaf2e234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registered backbones: \n",
      "- convnext_tiny\n",
      "- resnet50\n",
      "- resnext50_32x4d\n",
      "- swin_t\n",
      "- vit_b_16\n",
      "- vit_l_16\n",
      "\n",
      "Pretraining with backbone: vit_b_16\n",
      "Saved config for vit_b_16 at configs/pretrain_vit_b_16.json\n",
      "Downloading: \"https://download.pytorch.org/models/vit_b_16-c867db91.pth\" to /home/long/.cache/torch/hub/checkpoints/vit_b_16-c867db91.pth\n",
      "Downloading: \"https://download.pytorch.org/models/vit_b_16-c867db91.pth\" to /home/long/.cache/torch/hub/checkpoints/vit_b_16-c867db91.pth\n",
      "Downloading: \"https://download.pytorch.org/models/vit_b_16-c867db91.pth\" to /home/long/.cache/torch/hub/checkpoints/vit_b_16-c867db91.pth\n",
      "Downloading: \"https://download.pytorch.org/models/vit_b_16-c867db91.pth\" to /home/long/.cache/torch/hub/checkpoints/vit_b_16-c867db91.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 330M/330M [00:11<00:00, 31.1MB/s] \n",
      "100%|██████████| 330M/330M [00:11<00:00, 31.0MB/s]\n",
      "100%|██████████| 330M/330M [00:11<00:00, 29.6MB/s]\n",
      "100%|██████████| 330M/330M [00:11<00:00, 29.1MB/s]\n",
      "/home/long/code/dl_project1/src/wejepa/train/pretrain.py:230: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler(enabled=use_amp)\n",
      "/home/long/code/dl_project1/src/wejepa/train/pretrain.py:230: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler(enabled=use_amp)\n",
      "/home/long/code/dl_project1/src/wejepa/train/pretrain.py:230: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler(enabled=use_amp)\n",
      "/home/long/code/dl_project1/src/wejepa/train/pretrain.py:230: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler(enabled=use_amp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has 86,567,656 trainable parameters.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 57.1M/169M [00:00<00:01, 89.4MB/s]W1120 01:53:48.654000 2726638 torch/multiprocessing/spawn.py:174] Terminating process 2728889 via signal SIGTERM\n",
      "W1120 01:53:48.656000 2726638 torch/multiprocessing/spawn.py:174] Terminating process 2728892 via signal SIGTERM\n",
      "W1120 01:53:48.657000 2726638 torch/multiprocessing/spawn.py:174] Terminating process 2728894 via signal SIGTERM\n"
     ]
    },
    {
     "ename": "ProcessRaisedException",
     "evalue": "\n\n-- Process 2 terminated with the following error:\nTraceback (most recent call last):\n  File \"/home/long/code/environments/wejepa/lib/python3.12/site-packages/torch/multiprocessing/spawn.py\", line 95, in _wrap\n    fn(i, *args)\n  File \"/home/long/code/dl_project1/src/wejepa/train/pretrain.py\", line 231, in _train_worker\n    data_loader, sampler = create_pretraining_dataloader(cfg, rank=rank, world_size=world_size)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/long/code/dl_project1/src/wejepa/datasets/cifar.py\", line 107, in create_pretraining_dataloader\n    dataset = IJEPADataset(cfg, train=True, download=rank == 0)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/long/code/dl_project1/src/wejepa/datasets/cifar.py\", line 42, in __init__\n    self.dataset = torchvision.datasets.CIFAR100(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/long/code/environments/wejepa/lib/python3.12/site-packages/torchvision/datasets/cifar.py\", line 69, in __init__\n    raise RuntimeError(\"Dataset not found or corrupted. You can use download=True to download it\")\nRuntimeError: Dataset not found or corrupted. You can use download=True to download it\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mProcessRaisedException\u001b[39m                    Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     25\u001b[39m cfg_path.write_text(json.dumps(cfg.to_dict(), indent=\u001b[32m2\u001b[39m))\n\u001b[32m     26\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSaved config for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackbone\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcfg_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[43mlaunch_pretraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/dl_project1/src/wejepa/train/pretrain.py:290\u001b[39m, in \u001b[36mlaunch_pretraining\u001b[39m\u001b[34m(cfg)\u001b[39m\n\u001b[32m    288\u001b[39m     world_size = torch.cuda.device_count() \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m1\u001b[39m\n\u001b[32m    289\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m world_size > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m290\u001b[39m     \u001b[43mmp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mspawn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_train_worker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnprocs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    292\u001b[39m     _train_worker(\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, cfg.to_dict())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/environments/wejepa/lib/python3.12/site-packages/torch/multiprocessing/spawn.py:364\u001b[39m, in \u001b[36mspawn\u001b[39m\u001b[34m(fn, args, nprocs, join, daemon, start_method)\u001b[39m\n\u001b[32m    358\u001b[39m     msg = (\n\u001b[32m    359\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThis method only supports start_method=spawn (got: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart_method\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    360\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mTo use a different start_method use:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    361\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m torch.multiprocessing.start_processes(...)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    362\u001b[39m     )\n\u001b[32m    363\u001b[39m     warnings.warn(msg, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mstart_processes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnprocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdaemon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_method\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mspawn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/environments/wejepa/lib/python3.12/site-packages/torch/multiprocessing/spawn.py:320\u001b[39m, in \u001b[36mstart_processes\u001b[39m\u001b[34m(fn, args, nprocs, join, daemon, start_method, numa_options)\u001b[39m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[32m    319\u001b[39m \u001b[38;5;66;03m# Loop on join until it returns True or raises an exception.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m320\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    321\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/environments/wejepa/lib/python3.12/site-packages/torch/multiprocessing/spawn.py:220\u001b[39m, in \u001b[36mProcessContext.join\u001b[39m\u001b[34m(self, timeout, grace_period)\u001b[39m\n\u001b[32m    218\u001b[39m msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m-- Process \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_index\u001b[38;5;132;01m:\u001b[39;00m\u001b[33md\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m terminated with the following error:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    219\u001b[39m msg += original_trace\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m ProcessRaisedException(msg, error_index, failed_process.pid)\n",
      "\u001b[31mProcessRaisedException\u001b[39m: \n\n-- Process 2 terminated with the following error:\nTraceback (most recent call last):\n  File \"/home/long/code/environments/wejepa/lib/python3.12/site-packages/torch/multiprocessing/spawn.py\", line 95, in _wrap\n    fn(i, *args)\n  File \"/home/long/code/dl_project1/src/wejepa/train/pretrain.py\", line 231, in _train_worker\n    data_loader, sampler = create_pretraining_dataloader(cfg, rank=rank, world_size=world_size)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/long/code/dl_project1/src/wejepa/datasets/cifar.py\", line 107, in create_pretraining_dataloader\n    dataset = IJEPADataset(cfg, train=True, download=rank == 0)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/long/code/dl_project1/src/wejepa/datasets/cifar.py\", line 42, in __init__\n    self.dataset = torchvision.datasets.CIFAR100(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/long/code/environments/wejepa/lib/python3.12/site-packages/torchvision/datasets/cifar.py\", line 69, in __init__\n    raise RuntimeError(\"Dataset not found or corrupted. You can use download=True to download it\")\nRuntimeError: Dataset not found or corrupted. You can use download=True to download it\n"
     ]
    }
   ],
   "source": [
    "from wejepa.backbones import available_backbones\n",
    "from wejepa.config import IJepaConfig\n",
    "from wejepa import default_config, launch_pretraining, IJEPA_base\n",
    "from pathlib import Path\n",
    "import json\n",
    "from copy import deepcopy\n",
    "\n",
    "print(\"Registered backbones: \")\n",
    "for backbone in available_backbones():\n",
    "    print(f\"- {backbone}\")\n",
    "\n",
    "candidates = [\"vit_b_16\", \"swin_t\", \"convnext_tiny\"]\n",
    "for backbone in candidates:\n",
    "    print(f\"\\nPretraining with backbone: {backbone}\")\n",
    "\n",
    "    with open(\"hf224_config.json\", \"r\") as f:\n",
    "        cfg_dict = json.load(f)\n",
    "    cfg = IJepaConfig.from_dict(cfg_dict)\n",
    "\n",
    "    cfg.model.classification_backbone = backbone\n",
    "    cfg.model.classification_pretrained = True\n",
    "    cfg.hardware.output_dir = f\"./outputs/ijepa/{backbone}\"\n",
    "    cfg_path = Path(f\"configs/pretrain_{backbone}.json\")\n",
    "    cfg_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    cfg_path.write_text(json.dumps(cfg.to_dict(), indent=2))\n",
    "    print(f\"Saved config for {backbone} at {cfg_path}\")\n",
    "\n",
    "    launch_pretraining(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74790eb",
   "metadata": {},
   "source": [
    "### 6. Visualizing Backbone Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0a77ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "from wejepa.backbones import resolve_preprocess_transforms\n",
    "\n",
    "class HFImageDataset(Dataset):\n",
    "    def __init__(self, backbone_name: str, split: str = \"train[:256]\", label_field: str = \"label\"):\n",
    "        self.dataset = load_dataset(\"./data/tsbpp___fall2025_deeplearning\", split=split)\n",
    "        self.transform = resolve_preprocess_transforms(backbone_name)\n",
    "        # Some datasets may not provide labels; fall back to a single class for visualization.\n",
    "        self.label_field = label_field if label_field in self.dataset.features else None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.dataset[idx]\n",
    "        image = self.transform(sample[\"image\"])\n",
    "        label = sample[self.label_field] if self.label_field else 0\n",
    "        return image, label\n",
    "\n",
    "\n",
    "def build_dataloader(backbone_name: str, batch_size: int = 24, split: str = \"train[:192]\") -> DataLoader:\n",
    "    dataset = HFImageDataset(backbone_name=backbone_name, split=split)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59791046",
   "metadata": {},
   "source": [
    "### 7. Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7406f578",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from wejepa.analysis.visualization import (\n",
    "    extract_backbone_features,\n",
    "    plot_tsne_embeddings,\n",
    "    run_tsne_projection,\n",
    ")\n",
    "from wejepa.backbones import build_backbone\n",
    "\n",
    "backbone_names = [\"vit_b_16\", \"swin_t\", \"convnext_tiny\"]\n",
    "tsne_results = {}\n",
    "\n",
    "for backbone_name in backbone_names:\n",
    "    print(f\"Projecting embeddings for {backbone_name} ...\")\n",
    "    backbone, feature_dim = build_backbone(backbone_name, pretrained=True, freeze_backbone=True)\n",
    "\n",
    "    # Use a small slice of the dataset to keep visualization quick.\n",
    "    dataloader = build_dataloader(backbone_name, batch_size=24, split=\"train[:192]\")\n",
    "    features, labels = extract_backbone_features(backbone, dataloader, max_batches=4)\n",
    "\n",
    "    embedding = run_tsne_projection(features, perplexity=20.0, random_state=42)\n",
    "    fig = plot_tsne_embeddings(embedding, labels)\n",
    "    fig.suptitle(f\"{backbone_name} TSNE\", y=1.02)\n",
    "    plt.show()\n",
    "\n",
    "    tsne_results[backbone_name] = embedding"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
