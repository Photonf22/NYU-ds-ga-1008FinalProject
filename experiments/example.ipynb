{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc761ad1",
   "metadata": {},
   "source": [
    "# Example based on our README.md\n",
    "1. Dataset download\n",
    "2. Pre-training\n",
    "3. Fine-tuning\n",
    "4. Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9de0bef",
   "metadata": {},
   "source": [
    "\n",
    "### 1. Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1e8ab29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 'train' available under /home/long/PhD/Coursework/Deep_Learning/Project/Code/ijepa/experiments/data\n"
     ]
    }
   ],
   "source": [
    "# using the cli\n",
    "!python -m wejepa.datasets.download --dataset-root ./data --dataset-name tsbpp/fall2025_deeplearning --splits train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21635921",
   "metadata": {},
   "source": [
    "### 2. Pre-training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e90f233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<frozen runpy>:128: RuntimeWarning: 'wejepa.train.pretrain' found in sys.modules after import of package 'wejepa.train', but prior to execution of 'wejepa.train.pretrain'; this may result in unpredictable behaviour\n",
      "{\n",
      "  \"data\": {\n",
      "    \"dataset_root\": \"/home/long/PhD/Coursework/Deep_Learning/Project/Code/ijepa/experiments/data\",\n",
      "    \"dataset_name\": \"cifar10\",\n",
      "    \"image_size\": 32,\n",
      "    \"train_batch_size\": 256,\n",
      "    \"eval_batch_size\": 512,\n",
      "    \"num_workers\": 4,\n",
      "    \"pin_memory\": true,\n",
      "    \"persistent_workers\": true,\n",
      "    \"prefetch_factor\": 2,\n",
      "    \"crop_scale\": [\n",
      "      0.6,\n",
      "      1.0\n",
      "    ],\n",
      "    \"color_jitter\": 0.5,\n",
      "    \"use_color_distortion\": true,\n",
      "    \"use_horizontal_flip\": true,\n",
      "    \"normalization_mean\": [\n",
      "      0.5071,\n",
      "      0.4867,\n",
      "      0.4408\n",
      "    ],\n",
      "    \"normalization_std\": [\n",
      "      0.2675,\n",
      "      0.2565,\n",
      "      0.2761\n",
      "    ],\n",
      "    \"use_fake_data\": false,\n",
      "    \"fake_data_size\": 512\n",
      "  },\n",
      "  \"mask\": {\n",
      "    \"target_aspect_ratio\": [\n",
      "      0.75,\n",
      "      1.5\n",
      "    ],\n",
      "    \"target_scale\": [\n",
      "      0.15,\n",
      "      0.2\n",
      "    ],\n",
      "    \"context_aspect_ratio\": 1.0,\n",
      "    \"context_scale\": [\n",
      "      0.85,\n",
      "      1.0\n",
      "    ],\n",
      "    \"num_target_blocks\": 4\n",
      "  },\n",
      "  \"model\": {\n",
      "    \"img_size\": 32,\n",
      "    \"patch_size\": 4,\n",
      "    \"in_chans\": 3,\n",
      "    \"embed_dim\": 192,\n",
      "    \"enc_depth\": 6,\n",
      "    \"pred_depth\": 4,\n",
      "    \"num_heads\": 6,\n",
      "    \"post_emb_norm\": false,\n",
      "    \"layer_dropout\": 0.0\n",
      "  },\n",
      "  \"optimizer\": {\n",
      "    \"epochs\": 5,\n",
      "    \"warmup_epochs\": 1,\n",
      "    \"base_learning_rate\": 0.001,\n",
      "    \"start_learning_rate\": 0.0001,\n",
      "    \"final_learning_rate\": 1e-05,\n",
      "    \"weight_decay\": 0.05,\n",
      "    \"final_weight_decay\": 0.2,\n",
      "    \"betas\": [\n",
      "      0.9,\n",
      "      0.95\n",
      "    ],\n",
      "    \"eps\": 1e-08,\n",
      "    \"grad_clip_norm\": 1.0,\n",
      "    \"momentum_teacher\": 0.996,\n",
      "    \"momentum_teacher_final\": 1.0\n",
      "  },\n",
      "  \"hardware\": {\n",
      "    \"seed\": 42,\n",
      "    \"world_size\": null,\n",
      "    \"mixed_precision\": true,\n",
      "    \"compile_model\": false,\n",
      "    \"log_every\": 50,\n",
      "    \"checkpoint_every\": 1,\n",
      "    \"output_dir\": \"/home/long/PhD/Coursework/Deep_Learning/Project/Code/ijepa/experiments/outputs/ijepa\"\n",
      "  }\n",
      "}\n",
      "<frozen runpy>:128: RuntimeWarning: 'wejepa.train.pretrain' found in sys.modules after import of package 'wejepa.train', but prior to execution of 'wejepa.train.pretrain'; this may result in unpredictable behaviour\n",
      "/home/long/PhD/Coursework/Deep_Learning/Project/Code/ijepa/src/wejepa/train/pretrain.py:225: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler(enabled=use_amp)\n",
      "/home/long/PhD/Coursework/Deep_Learning/Project/Code/ijepa/src/wejepa/train/pretrain.py:163: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n",
      "Epoch 1 Iter 50/195 | Loss 0.2530 | 1276.6 img/s\n",
      "Epoch 1 Iter 100/195 | Loss 0.2099 | 1335.1 img/s\n",
      "Epoch 1 Iter 150/195 | Loss 0.1971 | 1359.7 img/s\n",
      "Saved checkpoint to outputs/ijepa/ijepa_epoch_0001.pt\n",
      "Epoch 1/5 | loss=0.1895\n",
      "Epoch 2 Iter 50/195 | Loss 0.1673 | 1433.5 img/s\n",
      "Epoch 2 Iter 100/195 | Loss 0.1605 | 1399.5 img/s\n",
      "Epoch 2 Iter 150/195 | Loss 0.1595 | 1408.7 img/s\n",
      "Saved checkpoint to outputs/ijepa/ijepa_epoch_0002.pt\n",
      "Epoch 2/5 | loss=0.1563\n",
      "Epoch 3 Iter 50/195 | Loss 0.1286 | 1431.7 img/s\n",
      "Epoch 3 Iter 100/195 | Loss 0.1243 | 1419.9 img/s\n",
      "Epoch 3 Iter 150/195 | Loss 0.1203 | 1430.6 img/s\n",
      "Saved checkpoint to outputs/ijepa/ijepa_epoch_0003.pt\n",
      "Epoch 3/5 | loss=0.1165\n",
      "Epoch 4 Iter 50/195 | Loss 0.0940 | 1431.4 img/s\n",
      "Epoch 4 Iter 100/195 | Loss 0.0930 | 1400.4 img/s\n",
      "Epoch 4 Iter 150/195 | Loss 0.0920 | 1406.9 img/s\n",
      "Saved checkpoint to outputs/ijepa/ijepa_epoch_0004.pt\n",
      "Epoch 4/5 | loss=0.0901\n",
      "Epoch 5 Iter 50/195 | Loss 0.0842 | 1480.7 img/s\n",
      "Epoch 5 Iter 100/195 | Loss 0.0838 | 1471.3 img/s\n",
      "Epoch 5 Iter 150/195 | Loss 0.0822 | 1465.7 img/s\n",
      "Saved checkpoint to outputs/ijepa/ijepa_epoch_0005.pt\n",
      "Epoch 5/5 | loss=0.0829\n"
     ]
    }
   ],
   "source": [
    "# using the cli\n",
    "\n",
    "# print the config\n",
    "!python -m wejepa.train.pretrain --config hf_config.json --print-config\n",
    "\n",
    "# pretrain the model\n",
    "!python -m wejepa.train.pretrain --config hf_config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52b311f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# programmatically\n",
    "from wejepa import default_config, launch_pretraining\n",
    "cfg = default_config()\n",
    "launch_pretraining(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffda647",
   "metadata": {},
   "source": [
    "### 3. Fine tuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2913c702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<frozen runpy>:128: RuntimeWarning: 'wejepa.train.finetune' found in sys.modules after import of package 'wejepa.train', but prior to execution of 'wejepa.train.finetune'; this may result in unpredictable behaviour\n",
      "[Linear probe] Epoch 1/10 | loss=4.5212 | train_acc=0.027 | val_acc=0.040\n",
      "[Linear probe] Epoch 2/10 | loss=4.4321 | train_acc=0.038 | val_acc=0.048\n",
      "[Linear probe] Epoch 3/10 | loss=4.3897 | train_acc=0.041 | val_acc=0.052\n",
      "[Linear probe] Epoch 4/10 | loss=4.3605 | train_acc=0.046 | val_acc=0.058\n",
      "[Linear probe] Epoch 5/10 | loss=4.3410 | train_acc=0.048 | val_acc=0.061\n",
      "[Linear probe] Epoch 6/10 | loss=4.3247 | train_acc=0.049 | val_acc=0.063\n",
      "[Linear probe] Epoch 7/10 | loss=4.3138 | train_acc=0.051 | val_acc=0.066\n",
      "[Linear probe] Epoch 8/10 | loss=4.3069 | train_acc=0.051 | val_acc=0.067\n",
      "[Linear probe] Epoch 9/10 | loss=4.2974 | train_acc=0.054 | val_acc=0.068\n",
      "[Linear probe] Epoch 10/10 | loss=4.2919 | train_acc=0.055 | val_acc=0.070\n"
     ]
    }
   ],
   "source": [
    "# using the cli\n",
    "!python -m wejepa.train.finetune \\\n",
    "    --checkpoint outputs/ijepa/ijepa_epoch_0005.pt \\\n",
    "    --epochs 10 \\\n",
    "    --batch-size 256 \\\n",
    "    --lr 3e-4 \\\n",
    "    --num-classes 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f283f657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# programmatically\n",
    "from wejepa.train import FinetuneConfig, train_linear_probe\n",
    "\n",
    "ft_cfg = FinetuneConfig(\n",
    "    checkpoint_path=\"outputs/ijepa/ijepa_epoch_0005.pt\",\n",
    "    epochs=5,\n",
    "    batch_size=128,\n",
    "    learning_rate=1e-3,\n",
    ")\n",
    "train_linear_probe(ft_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4317f0",
   "metadata": {},
   "source": [
    "### 4. Running Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88f0b938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: torch.Size([1, 3, 32, 32])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from datasets import load_dataset\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "from wejepa.train import load_backbone_from_checkpoint\n",
    "from wejepa import default_config\n",
    "\n",
    "cfg = default_config()\n",
    "backbone = load_backbone_from_checkpoint(\"outputs/ijepa/ijepa_epoch_0005.pt\", cfg)\n",
    "backbone.eval()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(cfg.data.image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(cfg.data.normalization_mean, cfg.data.normalization_std),\n",
    "])\n",
    "\n",
    "ds = load_dataset(\n",
    "    \"./data/tsbpp___fall2025_deeplearning\",\n",
    "    split=\"train\",\n",
    ")\n",
    "# grab an image from the dataset\n",
    "image = transform(ds[0][\"image\"]).unsqueeze(0)\n",
    "print(f\"Image shape: {image.shape}\")\n",
    "\n",
    "# remove batch dimension and convert to numpy\n",
    "img_np = image.squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
    "\n",
    "# undo normalization for display\n",
    "mean = np.array(cfg.data.normalization_mean)\n",
    "std = np.array(cfg.data.normalization_std)\n",
    "img_np = (img_np * std) + mean\n",
    "img_np = np.clip(img_np, 0, 1)\n",
    "\n",
    "plt.imshow(img_np)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "with torch.no_grad():\n",
    "    tokens = backbone(image)\n",
    "    pooled = tokens.mean(dim=1)  # embeddings for downstream heads\n",
    "\n",
    "# TODO: use the embeddings `pooled` for downstream tasks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ijepa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
