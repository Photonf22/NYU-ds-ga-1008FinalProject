{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc761ad1",
   "metadata": {},
   "source": [
    "# Example based on our README.md\n",
    "1. Dataset download\n",
    "2. Prepare dataset\n",
    "3. Pre-training\n",
    "4. Fine-tuning\n",
    "5. Different backbones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9de0bef",
   "metadata": {},
   "source": [
    "\n",
    "### Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1e8ab29",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading CUB-200-2011 from https://data.caltech.edu/records/65de6-vp158/files/CUB_200_2011.tgz...\n",
      "Download complete!\n",
      "Extracting CUB-200-2011 dataset...\n",
      "Extraction complete!\n",
      "Generating CUB-200 train/val/test splits\n",
      "Split 'train,test' available under /home/long/code/dl_project1/experiments/data\n"
     ]
    }
   ],
   "source": [
    "# using the cli\n",
    "\n",
    "# download class dataset\n",
    "#!python -m wejepa.datasets.download --dataset-root ./data --dataset-name tsbpp/fall2025_deeplearning --splits train\n",
    "\n",
    "# for development, download a small subset\n",
    "#!python -m wejepa.datasets.download --dataset-root ./data --dataset-name tsbpp/fall2025_deeplearning --splits 'train[:10]'\n",
    "\n",
    "# download the class pretrain dataset raw data\n",
    "#!python -m wejepa.datasets.download --dataset-root ./data --dataset-name tsbpp/fall2025_deeplearning --snapshot-download --splits train\n",
    "\n",
    "# download cifar100 dataset\n",
    "#!python -m wejepa.datasets.download --dataset-root ./data --dataset-name cifar100\n",
    "\n",
    "# download cub200 dataset\n",
    "!python -m wejepa.datasets.download --dataset-root ./data --dataset-name cub200 --splits train,test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793c8d98",
   "metadata": {},
   "source": [
    "### Inspect and Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2987b78c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# prepare raw images into huggingface dataset format (not needed with the current dataset structure)\n",
    "# !python -m wejepa.datasets.prepare_images --input-dir ./data/tsbpp_fall2025_deeplearning --output-dir ./data/tsbpp___fall2025_deeplearning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21635921",
   "metadata": {},
   "source": [
    "### Pre-training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e90f233",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Using the cli\n",
    "\n",
    "# Clear\n",
    "!export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\n",
    "\n",
    "# Train using default cifar100 config + custom ViT backbone\n",
    "# !python -m wejepa.train.pretrain --print-config     # print only\n",
    "# !python -m wejepa.train.pretrain                    # train\n",
    "\n",
    "# FIXME: bug when using .arrow files, the file path is not correctly set, workaround is to rename the arrow file\n",
    "#   cp fall2025_deeplearning-train.arrow tsbpp___fall2025_deeplearning-train.arrow\n",
    "\n",
    "# print where --config searches for config files\n",
    "# !python -m wejepa.train.pretrain --config hf224_config.json\n",
    "\n",
    "#!PYTHONWARNINGS=\"ignore::RuntimeWarning\" python -m wejepa.train.pretrain --config configs/pretrain_devel_tsbpp_224.json\n",
    "#!PYTHONWARNINGS=\"ignore::RuntimeWarning\" python -m wejepa.train.pretrain --config configs/pretrain_vit_b_16_tsbpp_224.json\n",
    "#!PYTHONWARNINGS=\"ignore::RuntimeWarning\" python -m wejepa.train.pretrain --config configs/pretrain_convnext_small_tsbpp_224.json\n",
    "!PYTHONWARNINGS=\"ignore::RuntimeWarning\" CUDA_VISIBLE_DEVICES=1,2,3 python -m wejepa.train.pretrain --config configs/pretrain_swin_s_tsbpp_224.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52b311f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# programmatically\n",
    "from wejepa import default_config, launch_pretraining\n",
    "cfg = default_config()\n",
    "launch_pretraining(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffda647",
   "metadata": {},
   "source": [
    "### Fine tuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2913c702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Linear probe] Epoch 1/20 | loss=5.2848 | train_acc=0.009 | val_acc=0.013\n",
      "[Linear probe] Epoch 2/20 | loss=5.1055 | train_acc=0.015 | val_acc=0.015\n",
      "[Linear probe] Epoch 3/20 | loss=5.0412 | train_acc=0.022 | val_acc=0.025\n",
      "[Linear probe] Epoch 4/20 | loss=4.9991 | train_acc=0.027 | val_acc=0.019\n",
      "[Linear probe] Epoch 5/20 | loss=4.9704 | train_acc=0.028 | val_acc=0.025\n",
      "[Linear probe] Epoch 6/20 | loss=4.9447 | train_acc=0.031 | val_acc=0.023\n",
      "[Linear probe] Epoch 7/20 | loss=4.9286 | train_acc=0.031 | val_acc=0.021\n",
      "[Linear probe] Epoch 8/20 | loss=4.9110 | train_acc=0.033 | val_acc=0.024\n",
      "[Linear probe] Epoch 9/20 | loss=4.8970 | train_acc=0.034 | val_acc=0.020\n",
      "[Linear probe] Epoch 10/20 | loss=4.8836 | train_acc=0.033 | val_acc=0.025\n",
      "[Linear probe] Epoch 11/20 | loss=4.8725 | train_acc=0.037 | val_acc=0.025\n",
      "[Linear probe] Epoch 12/20 | loss=4.8583 | train_acc=0.036 | val_acc=0.024\n",
      "[Linear probe] Epoch 13/20 | loss=4.8520 | train_acc=0.039 | val_acc=0.030\n",
      "[Linear probe] Epoch 14/20 | loss=4.8403 | train_acc=0.035 | val_acc=0.028\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "# using the cli\n",
    "!python -m wejepa.train.finetune \\\n",
    "    --checkpoint outputs/vit_b_16/ijepa_epoch_0026.pt \\\n",
    "    --epochs 20 \\\n",
    "    --batch-size 256 \\\n",
    "    --lr 3e-4 \\\n",
    "    --num-classes 200 \\\n",
    "    --config configs/finetune_vit_b_16_cub200_224.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32087b41-f80e-4ac3-baf9-ce8ab0230d28",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Fine-tune config: FinetuneConfig(ijepa=IJepaConfig(data=DataConfig(dataset_root='./data', dataset_name='cub200', dataset_dir=None, image_size=224, train_batch_size=256, eval_batch_size=512, num_workers=8, pin_memory=True, persistent_workers=True, prefetch_factor=2, crop_scale=(0.6, 1.0), color_jitter=None, use_color_distortion=False, use_horizontal_flip=False, normalization_mean=(0.5071, 0.4867, 0.4408), normalization_std=(0.2675, 0.2565, 0.2761), use_fake_data=False, fake_data_size=512, image_dir=None, image_list=None, labels=None), mask=MaskConfig(target_aspect_ratio=(0.75, 1.5), target_scale=(0.15, 0.2), context_aspect_ratio=1.0, context_scale=(0.85, 1.0), num_target_blocks=4), model=ModelConfig(img_size=224, patch_size=16, in_chans=3, embed_dim=768, enc_depth=6, pred_depth=4, num_heads=12, post_emb_norm=False, layer_dropout=0.0, classification_backbone='vit_b_16', classification_num_classes=200, classification_pretrained=True, model_bypass=True), optimizer=OptimizerConfig(epochs=5, warmup_epochs=1, base_learning_rate=0.001, start_learning_rate=0.0001, final_learning_rate=1e-05, weight_decay=0.05, final_weight_decay=0.2, betas=[0.9, 0.95], eps=1e-08, grad_clip_norm=1.0, momentum_teacher=0.996, momentum_teacher_final=1.0), hardware=HardwareConfig(seed=42, world_size=1, mixed_precision=True, compile_model=False, log_every=50, checkpoint_every=1, output_dir='./outputs/vit_b_16/finetune')), batch_size=256, epochs=20, learning_rate=0.0003, weight_decay=0.0, num_classes=200, num_workers=4, checkpoint_path='outputs/vit_b_16/ijepa_epoch_0026.pt', debug=True)\n",
      "[DEBUG] Using device cuda for fine-tuning\n",
      "[DEBUG] Using backbone 'vit_b_16' | hidden_dim=768 pretrained=True freeze_backbone=True image_size=224 patch_size=16 num_heads=12backbone spec=BackboneSpec(build_fn=<function vit_b_16 at 0x746f09cf5300>, weights=ViT_B_16_Weights.IMAGENET1K_V1, head_type='vit', default_image_size=224, default_patch_size=16, default_embed_dim=768, default_num_heads=12)\n",
      "[DEBUG] Loading checkpoint from outputs/vit_b_16/ijepa_epoch_0026.pt\n",
      "[DEBUG] Loaded student keys=74 teacher_present=True predictor_present=True\n",
      "[DEBUG] Loading CUB200Dataset from ./data split=train\n",
      "[DEBUG] Created train dataloader with batch_size=256 workers=8 shuffle=True dataset_len=8232\n",
      "[DEBUG] Loading CUB200Dataset from ./data split=val\n",
      "[DEBUG] Created eval dataloader with batch_size=256 workers=8 shuffle=False dataset_len=1727\n",
      "[DEBUG] First train batch: images=(256, 3, 224, 224) logits=(256, 200) loss=5.3921\n",
      "[DEBUG] Eval batch: images=(256, 3, 224, 224) logits=(256, 200)\n",
      "[Linear probe] Epoch 1/20 | loss=4.8897 | train_acc=0.077 | val_acc=0.180\n",
      "[DEBUG] First train batch: images=(256, 3, 224, 224) logits=(256, 200) loss=4.3723\n",
      "[DEBUG] Eval batch: images=(256, 3, 224, 224) logits=(256, 200)\n",
      "[Linear probe] Epoch 2/20 | loss=3.9365 | train_acc=0.286 | val_acc=0.310\n",
      "[DEBUG] First train batch: images=(256, 3, 224, 224) logits=(256, 200) loss=3.4911\n",
      "[DEBUG] Eval batch: images=(256, 3, 224, 224) logits=(256, 200)\n",
      "[Linear probe] Epoch 3/20 | loss=3.2767 | train_acc=0.430 | val_acc=0.415\n",
      "[DEBUG] First train batch: images=(256, 3, 224, 224) logits=(256, 200) loss=3.0604\n",
      "[DEBUG] Eval batch: images=(256, 3, 224, 224) logits=(256, 200)\n",
      "[Linear probe] Epoch 4/20 | loss=2.8264 | train_acc=0.512 | val_acc=0.464\n",
      "[DEBUG] First train batch: images=(256, 3, 224, 224) logits=(256, 200) loss=2.5330\n",
      "[DEBUG] Eval batch: images=(256, 3, 224, 224) logits=(256, 200)\n",
      "[Linear probe] Epoch 5/20 | loss=2.4812 | train_acc=0.578 | val_acc=0.505\n",
      "[DEBUG] First train batch: images=(256, 3, 224, 224) logits=(256, 200) loss=2.3359\n",
      "[DEBUG] Eval batch: images=(256, 3, 224, 224) logits=(256, 200)\n",
      "[Linear probe] Epoch 6/20 | loss=2.2206 | train_acc=0.622 | val_acc=0.532\n",
      "[DEBUG] First train batch: images=(256, 3, 224, 224) logits=(256, 200) loss=2.0753\n",
      "[DEBUG] Eval batch: images=(256, 3, 224, 224) logits=(256, 200)\n",
      "[Linear probe] Epoch 7/20 | loss=2.0259 | train_acc=0.651 | val_acc=0.555\n",
      "[DEBUG] First train batch: images=(256, 3, 224, 224) logits=(256, 200) loss=1.9393\n",
      "[DEBUG] Eval batch: images=(256, 3, 224, 224) logits=(256, 200)\n",
      "[Linear probe] Epoch 8/20 | loss=1.8687 | train_acc=0.672 | val_acc=0.570\n",
      "[DEBUG] First train batch: images=(256, 3, 224, 224) logits=(256, 200) loss=1.7898\n",
      "[DEBUG] Eval batch: images=(256, 3, 224, 224) logits=(256, 200)\n",
      "[Linear probe] Epoch 9/20 | loss=1.7256 | train_acc=0.692 | val_acc=0.582\n",
      "[DEBUG] First train batch: images=(256, 3, 224, 224) logits=(256, 200) loss=1.6528\n",
      "[DEBUG] Eval batch: images=(256, 3, 224, 224) logits=(256, 200)\n",
      "[Linear probe] Epoch 10/20 | loss=1.6138 | train_acc=0.709 | val_acc=0.598\n",
      "[DEBUG] First train batch: images=(256, 3, 224, 224) logits=(256, 200) loss=1.7274\n",
      "[DEBUG] Eval batch: images=(256, 3, 224, 224) logits=(256, 200)\n",
      "[Linear probe] Epoch 11/20 | loss=1.5164 | train_acc=0.727 | val_acc=0.610\n",
      "[DEBUG] First train batch: images=(256, 3, 224, 224) logits=(256, 200) loss=1.4130\n",
      "[DEBUG] Eval batch: images=(256, 3, 224, 224) logits=(256, 200)\n",
      "[Linear probe] Epoch 12/20 | loss=1.4285 | train_acc=0.742 | val_acc=0.616\n",
      "[DEBUG] First train batch: images=(256, 3, 224, 224) logits=(256, 200) loss=1.2919\n",
      "[DEBUG] Eval batch: images=(256, 3, 224, 224) logits=(256, 200)\n",
      "[Linear probe] Epoch 13/20 | loss=1.3521 | train_acc=0.751 | val_acc=0.625\n",
      "[DEBUG] First train batch: images=(256, 3, 224, 224) logits=(256, 200) loss=1.2363\n",
      "[DEBUG] Eval batch: images=(256, 3, 224, 224) logits=(256, 200)\n",
      "[Linear probe] Epoch 14/20 | loss=1.2945 | train_acc=0.765 | val_acc=0.626\n",
      "[DEBUG] First train batch: images=(256, 3, 224, 224) logits=(256, 200) loss=1.3342\n",
      "[DEBUG] Eval batch: images=(256, 3, 224, 224) logits=(256, 200)\n",
      "[Linear probe] Epoch 15/20 | loss=1.2319 | train_acc=0.774 | val_acc=0.630\n",
      "[DEBUG] First train batch: images=(256, 3, 224, 224) logits=(256, 200) loss=1.1793\n",
      "[DEBUG] Eval batch: images=(256, 3, 224, 224) logits=(256, 200)\n",
      "[Linear probe] Epoch 16/20 | loss=1.1752 | train_acc=0.786 | val_acc=0.641\n",
      "[DEBUG] First train batch: images=(256, 3, 224, 224) logits=(256, 200) loss=1.1462\n",
      "[DEBUG] Eval batch: images=(256, 3, 224, 224) logits=(256, 200)\n",
      "[Linear probe] Epoch 17/20 | loss=1.1293 | train_acc=0.794 | val_acc=0.640\n",
      "[DEBUG] First train batch: images=(256, 3, 224, 224) logits=(256, 200) loss=1.0883\n",
      "[DEBUG] Eval batch: images=(256, 3, 224, 224) logits=(256, 200)\n",
      "[Linear probe] Epoch 18/20 | loss=1.0842 | train_acc=0.800 | val_acc=0.649\n",
      "[DEBUG] First train batch: images=(256, 3, 224, 224) logits=(256, 200) loss=1.0329\n",
      "[DEBUG] Eval batch: images=(256, 3, 224, 224) logits=(256, 200)\n",
      "[Linear probe] Epoch 19/20 | loss=1.0442 | train_acc=0.808 | val_acc=0.655\n",
      "[DEBUG] First train batch: images=(256, 3, 224, 224) logits=(256, 200) loss=1.0502\n",
      "[DEBUG] Eval batch: images=(256, 3, 224, 224) logits=(256, 200)\n",
      "[Linear probe] Epoch 20/20 | loss=1.0060 | train_acc=0.814 | val_acc=0.656\n"
     ]
    }
   ],
   "source": [
    "!python -m wejepa.train.finetune \\\n",
    "    --checkpoint outputs/vit_b_16/ijepa_epoch_0026.pt \\\n",
    "    --epochs 20 \\\n",
    "    --batch-size 256 \\\n",
    "    --lr 3e-4 \\\n",
    "    --num-classes 200 \\\n",
    "    --config configs/finetune_pretrained_vit_b_16_cub200_224.json --debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f476ce-06e8-48e8-b37c-28d60d12ab55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Linear probe] Epoch 1/20 | loss=5.2838 | train_acc=0.013 | val_acc=0.017\n"
     ]
    }
   ],
   "source": [
    "!python -m wejepa.train.finetune \\\n",
    "    --checkpoint outputs/vit_b_16/ijepa_epoch_0026.pt \\\n",
    "    --epochs 20 \\\n",
    "    --batch-size 256 \\\n",
    "    --lr 3e-4 \\\n",
    "    --num-classes 200 \\\n",
    "    --config configs/finetune_pretrained__no_bypass_vit_b_16_cub200_224.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c18a56-30e1-4da8-a8b0-f136ab0d78e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m wejepa.train.finetune \\\n",
    "    --checkpoint outputs/vit_b_16/ijepa_epoch_0026.pt \\\n",
    "    --epochs 20 \\\n",
    "    --batch-size 256 \\\n",
    "    --lr 3e-4 \\\n",
    "    --num-classes 200 \\\n",
    "    --config configs/finetune_pretrained__no_bypass_vit_b_16_jepa_cub200_224.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f283f657",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# programmatically\n",
    "from wejepa.train import FinetuneConfig, train_linear_probe\n",
    "\n",
    "ft_cfg = FinetuneConfig(\n",
    "    checkpoint_path=\"outputs/ijepa/ijepa_epoch_0005.pt\",\n",
    "    epochs=5,\n",
    "    batch_size=128,\n",
    "    learning_rate=1e-3,\n",
    ")\n",
    "train_linear_probe(ft_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81e75d3",
   "metadata": {},
   "source": [
    "### Different Backbones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a884a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "\n",
    "from wejepa.backbones import adapt_config_for_backbone, available_backbones\n",
    "from wejepa.config import IJepaConfig\n",
    "from wejepa import default_config, launch_pretraining, IJEPA_base\n",
    "\n",
    "print(\"Registered backbones: \")\n",
    "for backbone in available_backbones():\n",
    "    print(f\"- {backbone}\")\n",
    "\n",
    "candidates = [\"vit_b_16\", \"swin_t\", \"convnext_tiny\"]\n",
    "for backbone in candidates:\n",
    "    print(f\"\\nPretraining with backbone: {backbone}\")\n",
    "\n",
    "for backbone in available_backbones():\n",
    "    cfg = adapt_config_for_backbone(default_config(), backbone)\n",
    "    print(f\"\\nBackbone: {backbone}\")\n",
    "    print(f\"Image size: {cfg.model.img_size} | Patch size: {cfg.model.patch_size}\")\n",
    "\n",
    "    model = IJEPA_base(\n",
    "        img_size=cfg.model.img_size,\n",
    "        patch_size=cfg.model.patch_size,\n",
    "        in_chans=cfg.model.in_chans,\n",
    "        embed_dim=cfg.model.embed_dim,\n",
    "        enc_depth=cfg.model.enc_depth,\n",
    "        pred_depth=cfg.model.pred_depth,\n",
    "        num_heads=cfg.model.num_heads,\n",
    "        backbone=cfg.model.classification_backbone,\n",
    "        pretrained=cfg.model.classification_pretrained,\n",
    "    )\n",
    "\n",
    "    print(f\"Total trainable params: {model.count_trainable_parameters() / 1e6:.2f}M\")\n",
    "    print(f\"Student + predictor params: {model.count_parameters() / 1e6:.2f}M\")\n",
    "\n",
    "    dummy = torch.randn(1, cfg.model.in_chans, cfg.model.img_size, cfg.model.img_size)\n",
    "    preds, targets = model(dummy)\n",
    "    print(f\"Pred shape: {tuple(preds.shape)} | Target shape: {tuple(targets.shape)}\")\n",
    "    print(json.dumps(cfg.to_dict(), indent=2))\n",
    "\n",
    "    cfg.hardware.output_dir = f\"./outputs/ijepa/{backbone}\"\n",
    "    cfg_path = Path(f\"configs/pretrain_{backbone}.json\")\n",
    "    cfg_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    cfg_path.write_text(json.dumps(cfg.to_dict(), indent=2))\n",
    "    print(f\"Saved config for {backbone} at {cfg_path}\")\n",
    "\n",
    "    # launch_pretraining(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b4a93a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
