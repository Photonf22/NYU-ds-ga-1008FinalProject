{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc761ad1",
   "metadata": {},
   "source": [
    "# Example based on our README.md\n",
    "1. Dataset download\n",
    "2. Pre-training\n",
    "3. Fine-tuning\n",
    "4. Different backbones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9de0bef",
   "metadata": {},
   "source": [
    "\n",
    "### 1. Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e8ab29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 'train' available under /home/long/PhD/Coursework/Deep_Learning/Project/Code/ijepa/experiments/data\n",
      "Split 'train[:10]' available under /home/long/PhD/Coursework/Deep_Learning/Project/Code/ijepa/experiments/data\n",
      "Downloading (incomplete total...): 0.00B [00:00, ?B/s]\n",
      "Fetching 6 files: 100%|█████████████████████████| 6/6 [00:00<00:00, 3965.62it/s]\u001b[A\n",
      "Download complete: : 0.00B [00:00, ?B/s]              \n",
      "Download complete: : 0.00B [00:01, ?B/s]                  | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Extracted /home/long/PhD/Coursework/Deep_Learning/Project/Code/ijepa/experiments/data/tsbpp_fall2025_deeplearning/cc3m_96px_part2.zip\n",
      "\n",
      "Extracting ZIP files:  20%|████▌                  | 1/5 [00:06<00:25,  6.48s/it]\u001b[AExtracted /home/long/PhD/Coursework/Deep_Learning/Project/Code/ijepa/experiments/data/tsbpp_fall2025_deeplearning/cc3m_96px_part3.zip\n",
      "\n",
      "Extracting ZIP files:  40%|█████████▏             | 2/5 [00:12<00:19,  6.39s/it]\u001b[AExtracted /home/long/PhD/Coursework/Deep_Learning/Project/Code/ijepa/experiments/data/tsbpp_fall2025_deeplearning/cc3m_96px_part1.zip\n",
      "\n",
      "Extracting ZIP files:  60%|█████████████▊         | 3/5 [00:19<00:12,  6.38s/it]\u001b[AExtracted /home/long/PhD/Coursework/Deep_Learning/Project/Code/ijepa/experiments/data/tsbpp_fall2025_deeplearning/cc3m_96px_part5.zip\n",
      "\n",
      "Extracting ZIP files:  80%|██████████████████▍    | 4/5 [00:25<00:06,  6.40s/it]\u001b[AExtracted /home/long/PhD/Coursework/Deep_Learning/Project/Code/ijepa/experiments/data/tsbpp_fall2025_deeplearning/cc3m_96px_part4.zip\n",
      "\n",
      "Extracting ZIP files: 100%|███████████████████████| 5/5 [00:31<00:00,  6.40s/it]\u001b[A\n",
      "Extracting TAR files: 0it [00:00, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/home/long/PhD/Coursework/Deep_Learning/Project/Code/ijepa/src/wejepa/datasets/download.py\", line 185, in <module>\n",
      "    main()\n",
      "  File \"/home/long/PhD/Coursework/Deep_Learning/Project/Code/ijepa/src/wejepa/datasets/download.py\", line 176, in main\n",
      "    downloads = download(args.dataset_root, \n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/long/PhD/Coursework/Deep_Learning/Project/Code/ijepa/src/wejepa/datasets/download.py\", line 119, in download\n",
      "    datasets.load_dataset(dataset_name, split=split, cache_dir=str(root))\n",
      "  File \"/home/long/PhD/Environments/ijepa/lib/python3.12/site-packages/datasets/load.py\", line 1429, in load_dataset\n",
      "    ds = builder_instance.as_dataset(split=split, verification_mode=verification_mode, in_memory=keep_in_memory)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/long/PhD/Environments/ijepa/lib/python3.12/site-packages/datasets/builder.py\", line 1090, in as_dataset\n",
      "    datasets = map_nested(\n",
      "               ^^^^^^^^^^^\n",
      "  File \"/home/long/PhD/Environments/ijepa/lib/python3.12/site-packages/datasets/utils/py_utils.py\", line 493, in map_nested\n",
      "    mapped = function(data_struct)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/long/PhD/Environments/ijepa/lib/python3.12/site-packages/datasets/builder.py\", line 1120, in _build_single_dataset\n",
      "    ds = self._as_dataset(\n",
      "         ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/long/PhD/Environments/ijepa/lib/python3.12/site-packages/datasets/builder.py\", line 1194, in _as_dataset\n",
      "    dataset_kwargs = ArrowReader(cache_dir, self.info).read(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/long/PhD/Environments/ijepa/lib/python3.12/site-packages/datasets/arrow_reader.py\", line 248, in read\n",
      "    files = self.get_file_instructions(name, instructions, split_infos)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/long/PhD/Environments/ijepa/lib/python3.12/site-packages/datasets/arrow_reader.py\", line 221, in get_file_instructions\n",
      "    file_instructions = make_file_instructions(\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/long/PhD/Environments/ijepa/lib/python3.12/site-packages/datasets/arrow_reader.py\", line 130, in make_file_instructions\n",
      "    absolute_instructions = instruction.to_absolute(name2len)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/long/PhD/Environments/ijepa/lib/python3.12/site-packages/datasets/arrow_reader.py\", line 620, in to_absolute\n",
      "    return [_rel_to_abs_instr(rel_instr, name2len) for rel_instr in self._relative_instructions]\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/long/PhD/Environments/ijepa/lib/python3.12/site-packages/datasets/arrow_reader.py\", line 437, in _rel_to_abs_instr\n",
      "    raise ValueError(f'Unknown split \"{split}\". Should be one of {list(name2len)}.')\n",
      "ValueError: Unknown split \"test\". Should be one of ['train'].\n",
      "Split 'train' available under /home/long/PhD/Coursework/Deep_Learning/Project/Code/ijepa/experiments/data\n",
      "Split 'test' available under /home/long/PhD/Coursework/Deep_Learning/Project/Code/ijepa/experiments/data\n",
      "Split 'train' available under /home/long/PhD/Coursework/Deep_Learning/Project/Code/ijepa/experiments/data\n"
     ]
    }
   ],
   "source": [
    "# using the cli\n",
    "\n",
    "# download class dataset\n",
    "!python -m wejepa.datasets.download --dataset-root ./data --dataset-name tsbpp/fall2025_deeplearning --splits train\n",
    "\n",
    "# for development, download a small subset\n",
    "!python -m wejepa.datasets.download --dataset-root ./data --dataset-name tsbpp/fall2025_deeplearning --splits 'train[:10]'\n",
    "\n",
    "# download the class pretrain dataset raw data\n",
    "!python -m wejepa.datasets.download --dataset-root ./data --dataset-name tsbpp/fall2025_deeplearning --snapshot-download --splits train\n",
    "\n",
    "# download cifar100 dataset\n",
    "!python -m wejepa.datasets.download --dataset-root ./data --dataset-name cifar100\n",
    "\n",
    "# download cub200 dataset\n",
    "!python -m wejepa.datasets.download --dataset-root ./data --dataset-name cub200 --splits train,test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21635921",
   "metadata": {},
   "source": [
    "### 2. Pre-training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e90f233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the cli\n",
    "\n",
    "# Clear\n",
    "!export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\n",
    "\n",
    "# Train using default cifar100 config + custom ViT backbone\n",
    "# !python -m wejepa.train.pretrain --print-config     # print only\n",
    "# !python -m wejepa.train.pretrain                    # train\n",
    "\n",
    "# FIXME: bug when using .arrow files, the file path is not correctly set, workaround is to rename the arrow file\n",
    "#   cp fall2025_deeplearning-train.arrow tsbpp___fall2025_deeplearning-train.arrow\n",
    "\n",
    "# print where --config searches for config files\n",
    "# !python -m wejepa.train.pretrain --config hf224_config.json\n",
    "\n",
    "!python -m wejepa.train.pretrain --config hf224_config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52b311f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# programmatically\n",
    "from wejepa import default_config, launch_pretraining\n",
    "cfg = default_config()\n",
    "launch_pretraining(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffda647",
   "metadata": {},
   "source": [
    "### 3. Fine tuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2913c702",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# using the cli\n",
    "!python -m wejepa.train.finetune \\\n",
    "    --checkpoint outputs/ijepa/ijepa_epoch_0005.pt \\\n",
    "    --epochs 10 \\\n",
    "    --batch-size 256 \\\n",
    "    --lr 3e-4 \\\n",
    "    --num-classes 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f283f657",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# programmatically\n",
    "from wejepa.train import FinetuneConfig, train_linear_probe\n",
    "\n",
    "ft_cfg = FinetuneConfig(\n",
    "    checkpoint_path=\"outputs/ijepa/ijepa_epoch_0005.pt\",\n",
    "    epochs=5,\n",
    "    batch_size=128,\n",
    "    learning_rate=1e-3,\n",
    ")\n",
    "train_linear_probe(ft_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81e75d3",
   "metadata": {},
   "source": [
    "### 4. Different Backbones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a884a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "\n",
    "from wejepa.backbones import adapt_config_for_backbone, available_backbones\n",
    "from wejepa.config import IJepaConfig\n",
    "from wejepa import default_config, launch_pretraining, IJEPA_base\n",
    "\n",
    "print(\"Registered backbones: \")\n",
    "for backbone in available_backbones():\n",
    "    print(f\"- {backbone}\")\n",
    "\n",
    "candidates = [\"vit_b_16\", \"swin_t\", \"convnext_tiny\"]\n",
    "for backbone in candidates:\n",
    "    print(f\"\\nPretraining with backbone: {backbone}\")\n",
    "\n",
    "for backbone in available_backbones():\n",
    "    cfg = adapt_config_for_backbone(default_config(), backbone)\n",
    "    print(f\"\\nBackbone: {backbone}\")\n",
    "    print(f\"Image size: {cfg.model.img_size} | Patch size: {cfg.model.patch_size}\")\n",
    "\n",
    "    model = IJEPA_base(\n",
    "        img_size=cfg.model.img_size,\n",
    "        patch_size=cfg.model.patch_size,\n",
    "        in_chans=cfg.model.in_chans,\n",
    "        embed_dim=cfg.model.embed_dim,\n",
    "        enc_depth=cfg.model.enc_depth,\n",
    "        pred_depth=cfg.model.pred_depth,\n",
    "        num_heads=cfg.model.num_heads,\n",
    "        backbone=cfg.model.classification_backbone,\n",
    "        pretrained=cfg.model.classification_pretrained,\n",
    "    )\n",
    "\n",
    "    print(f\"Total trainable params: {model.count_trainable_parameters() / 1e6:.2f}M\")\n",
    "    print(f\"Student + predictor params: {model.count_parameters() / 1e6:.2f}M\")\n",
    "\n",
    "    dummy = torch.randn(1, cfg.model.in_chans, cfg.model.img_size, cfg.model.img_size)\n",
    "    preds, targets = model(dummy)\n",
    "    print(f\"Pred shape: {tuple(preds.shape)} | Target shape: {tuple(targets.shape)}\")\n",
    "    print(json.dumps(cfg.to_dict(), indent=2))\n",
    "\n",
    "    cfg.hardware.output_dir = f\"./outputs/ijepa/{backbone}\"\n",
    "    cfg_path = Path(f\"configs/pretrain_{backbone}.json\")\n",
    "    cfg_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    cfg_path.write_text(json.dumps(cfg.to_dict(), indent=2))\n",
    "    print(f\"Saved config for {backbone} at {cfg_path}\")\n",
    "\n",
    "    # launch_pretraining(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b4a93a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ijepa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
