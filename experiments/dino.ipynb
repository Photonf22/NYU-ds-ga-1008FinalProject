{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0",
      "metadata": {
        "id": "0"
      },
      "source": [
        "This example requires the following dependencies to be installed:\n",
        "pip install lightly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "1",
      "metadata": {
        "id": "1"
      },
      "outputs": [],
      "source": [
        "# !pip install lightly"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2",
      "metadata": {
        "id": "2"
      },
      "source": [
        "Note: The model and training settings do not follow the reference settings\n",
        "from the paper. The settings are chosen such that the example can easily be\n",
        "run on a small dataset with a single GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "3",
      "metadata": {
        "id": "3"
      },
      "outputs": [],
      "source": [
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "4",
      "metadata": {
        "id": "4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "5",
      "metadata": {
        "id": "5"
      },
      "outputs": [],
      "source": [
        "from lightly.loss import DINOLoss\n",
        "from lightly.models.modules import DINOProjectionHead\n",
        "from lightly.models.utils import deactivate_requires_grad, update_momentum\n",
        "from lightly.transforms.dino_transform import DINOTransform\n",
        "from lightly.utils.scheduler import cosine_schedule"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from huggingface_hub import snapshot_download\n",
        "\n",
        "\n",
        "class RawImageDataset(Dataset):\n",
        "    \"\"\"Dataset that loads images directly from raw files.\"\"\"\n",
        "\n",
        "    def __init__(self, root_dir, transform=None, image_extensions=None):\n",
        "        self.root_dir = Path(root_dir)\n",
        "        self.transform = transform\n",
        "\n",
        "        if image_extensions is None:\n",
        "            image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.JPEG', '*.JPG', '*.PNG']\n",
        "\n",
        "        # Find all image files\n",
        "        self.image_paths = []\n",
        "        print(f\"Searching for images in: {self.root_dir}\")\n",
        "\n",
        "        for pattern in image_extensions:\n",
        "            found = glob.glob(str(self.root_dir / '**' / pattern), recursive=True)\n",
        "            self.image_paths.extend(found)\n",
        "            if found:\n",
        "                print(f\"  Found {len(found)} {pattern} files\")\n",
        "\n",
        "        self.image_paths.sort()\n",
        "        print(f\"Total images found: {len(self.image_paths)}\")\n",
        "\n",
        "        if len(self.image_paths) == 0:\n",
        "            print(\"\\nWarning: No images found. Directory structure (first 20 items):\")\n",
        "            for item in sorted(self.root_dir.rglob('*'))[:20]:\n",
        "                print(f\"  {item}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # import pdb\n",
        "        # pdb.set_trace()\n",
        "        img_path = self.image_paths[idx]\n",
        "\n",
        "        try:\n",
        "            img = Image.open(img_path).convert('RGB')\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {img_path}: {e}\")\n",
        "            img = Image.new('RGB', (96, 96), color='black')\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "            # import pdb; pdb.set_trace()\n",
        "            # print(img.shape,\"old image shape\")\n",
        "            # img = img[0]\n",
        "            # print(img.shape,\"new image shape\")\n",
        "\n",
        "        return img\n",
        "\n",
        "\n",
        "def download_and_extract_dataset(repo_id, cache_dir=None, max_workers=4):\n",
        "    \"\"\"Download and extract dataset from HuggingFace.\"\"\"\n",
        "\n",
        "    print(f\"Downloading dataset from {repo_id}...\")\n",
        "\n",
        "    try:\n",
        "        local_dir = snapshot_download(\n",
        "            repo_id=repo_id,\n",
        "            repo_type=\"dataset\",\n",
        "            cache_dir=cache_dir,\n",
        "            max_workers=max_workers,\n",
        "            resume_download=True,\n",
        "        )\n",
        "        print(f\"Dataset downloaded to: {local_dir}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error during download: {e}\")\n",
        "        print(\"Retrying with single worker...\")\n",
        "        local_dir = snapshot_download(\n",
        "            repo_id=repo_id,\n",
        "            repo_type=\"dataset\",\n",
        "            cache_dir=cache_dir,\n",
        "            max_workers=1,\n",
        "            resume_download=True,\n",
        "        )\n",
        "        print(f\"Dataset downloaded to: {local_dir}\")\n",
        "\n",
        "    # Extract zip files if present\n",
        "    local_path = Path(local_dir)\n",
        "    zip_files = list(local_path.glob('*.zip'))\n",
        "\n",
        "    if zip_files:\n",
        "        print(f\"\\nFound {len(zip_files)} zip files. Extracting...\")\n",
        "        extract_dir = local_path / 'extracted'\n",
        "        extract_dir.mkdir(exist_ok=True)\n",
        "\n",
        "        # for zip_file in zip_files:\n",
        "        #     print(f\"  Extracting {zip_file.name}...\")\n",
        "        #     try:\n",
        "        #         with zipfile.ZipFile(zip_file, 'r') as zf:\n",
        "        #             zf.extractall(extract_dir)\n",
        "        #         print(\"    ✓ Extracted successfully\")\n",
        "        #     except Exception as e:\n",
        "        #         print(f\"    ✗ Error: {e}\")\n",
        "\n",
        "        return extract_dir\n",
        "    else:\n",
        "        print(\"No zip files found, using directory as-is\")\n",
        "        return local_path\n",
        "\n"
      ],
      "metadata": {
        "id": "bJWwZr0Q6oLu"
      },
      "id": "bJWwZr0Q6oLu",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and extract dataset\n",
        "data_dir = download_and_extract_dataset(\n",
        "    repo_id=\"tsbpp/fall2025_deeplearning\",\n",
        "    cache_dir=None,\n",
        "    max_workers=4\n",
        ")\n",
        "\n",
        "# Create transform\n",
        "transform = DINOTransform()\n",
        "# transform = get_mae_transform()\n",
        "\n",
        "# Create dataset\n",
        "dataset = RawImageDataset(data_dir, transform=transform)\n",
        "print(f\"\\nDataset ready with {len(dataset)} images\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260,
          "referenced_widgets": [
            "9cfd55e334fc4943b4674f3ba8502249",
            "f5ac001d79c84bc697ca2180371a8587",
            "5cc70c49ab194fb2a3891387b414ae69",
            "4bbed79e5c47409b92cf09d5d440034e",
            "18901c5c91c64449ab3a656ca98da3ab",
            "953a58a23a7c49a7a196c85d31bfc3de",
            "b7784a2864f548a585841176447886c4",
            "048804520ca544ea9580b6e1752033e7",
            "88a7c0f2334e4b7c859eab2ec0a6b364",
            "93c81c0b7064417186bd7dc336b37318",
            "866161d5edc9424f8144f6316f49bc47"
          ]
        },
        "id": "SHbyXBSR64na",
        "outputId": "ebbe8354-fcc9-41f1-d651-6c42d3633d70"
      },
      "id": "SHbyXBSR64na",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dataset from tsbpp/fall2025_deeplearning...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9cfd55e334fc4943b4674f3ba8502249"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset downloaded to: /root/.cache/huggingface/hub/datasets--tsbpp--fall2025_deeplearning/snapshots/7b14dd4385d982457822e8e96c5081a30da146d8\n",
            "\n",
            "Found 5 zip files. Extracting...\n",
            "Searching for images in: /root/.cache/huggingface/hub/datasets--tsbpp--fall2025_deeplearning/snapshots/7b14dd4385d982457822e8e96c5081a30da146d8/extracted\n",
            "  Found 500000 *.jpg files\n",
            "Total images found: 500000\n",
            "\n",
            "Dataset ready with 500000 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "6",
      "metadata": {
        "id": "6"
      },
      "outputs": [],
      "source": [
        "class DINO(torch.nn.Module):\n",
        "    def __init__(self, backbone, input_dim):\n",
        "        super().__init__()\n",
        "        self.student_backbone = backbone\n",
        "        self.student_head = DINOProjectionHead(\n",
        "            input_dim, 512, 64, 2048, freeze_last_layer=1\n",
        "        )\n",
        "        self.teacher_backbone = copy.deepcopy(backbone)\n",
        "        self.teacher_head = DINOProjectionHead(input_dim, 512, 64, 2048)\n",
        "        deactivate_requires_grad(self.teacher_backbone)\n",
        "        deactivate_requires_grad(self.teacher_head)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.student_backbone(x).flatten(start_dim=1)\n",
        "        z = self.student_head(y)\n",
        "        return z\n",
        "\n",
        "    def forward_teacher(self, x):\n",
        "        y = self.teacher_backbone(x).flatten(start_dim=1)\n",
        "        z = self.teacher_head(y)\n",
        "        return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "7",
      "metadata": {
        "id": "7"
      },
      "outputs": [],
      "source": [
        "resnet = torchvision.models.resnet18()\n",
        "backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
        "input_dim = 512\n",
        "# instead of a resnet you can also use a vision transformer backbone as in the\n",
        "# original paper (you might have to reduce the batch size in this case):\n",
        "# backbone = torch.hub.load('facebookresearch/dino:main', 'dino_vits16', pretrained=False)\n",
        "# input_dim = backbone.embed_dim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "8",
      "metadata": {
        "id": "8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01205f27-6085-4d04-911c-7861f5db6c8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/utils/weight_norm.py:144: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
            "  WeightNorm.apply(module, name, dim)\n"
          ]
        }
      ],
      "source": [
        "model = DINO(backbone, input_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "9",
      "metadata": {
        "id": "9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3e9da54-b794-4ddf-b90f-257c0be23215"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DINO(\n",
              "  (student_backbone): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (4): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (5): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (6): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (7): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  )\n",
              "  (student_head): DINOProjectionHead(\n",
              "    (layers): Sequential(\n",
              "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
              "      (1): GELU(approximate='none')\n",
              "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
              "      (3): GELU(approximate='none')\n",
              "      (4): Linear(in_features=512, out_features=64, bias=True)\n",
              "    )\n",
              "    (last_layer): Linear(in_features=64, out_features=2048, bias=False)\n",
              "  )\n",
              "  (teacher_backbone): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (4): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (5): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (6): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (7): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  )\n",
              "  (teacher_head): DINOProjectionHead(\n",
              "    (layers): Sequential(\n",
              "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
              "      (1): GELU(approximate='none')\n",
              "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
              "      (3): GELU(approximate='none')\n",
              "      (4): Linear(in_features=512, out_features=64, bias=True)\n",
              "    )\n",
              "    (last_layer): Linear(in_features=64, out_features=2048, bias=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_params(module):\n",
        "    return sum(p.numel() for p in module.parameters())\n",
        "\n",
        "total_params = count_params(model)\n",
        "student_backbone_params = count_params(model.student_backbone)\n",
        "student_head_params = count_params(model.student_head)\n",
        "teacher_backbone_params = count_params(model.teacher_backbone)\n",
        "teacher_head_params = count_params(model.teacher_head)\n",
        "\n",
        "student_total = student_backbone_params + student_head_params\n",
        "teacher_total = teacher_backbone_params + teacher_head_params\n",
        "\n",
        "print(f\"Total params (student + teacher + heads): {total_params:,}\")\n",
        "print(f\"  Student backbone: {student_backbone_params:,}\")\n",
        "print(f\"  Student head:     {student_head_params:,}\")\n",
        "print(f\"  Student TOTAL:    {student_total:,}\")\n",
        "print(f\"  Teacher backbone: {teacher_backbone_params:,}\")\n",
        "print(f\"  Teacher head:     {teacher_head_params:,}\")\n",
        "print(f\"  Teacher TOTAL:    {teacher_total:,}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HS3dE7eSDZMn",
        "outputId": "d6f71511-7cdc-400a-abc9-88cdd6e40624"
      },
      "id": "HS3dE7eSDZMn",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total params (student + teacher + heads): 23,735,552\n",
            "  Student backbone: 11,176,512\n",
            "  Student head:     691,264\n",
            "  Student TOTAL:    11,867,776\n",
            "  Teacher backbone: 11,176,512\n",
            "  Teacher head:     691,264\n",
            "  Teacher TOTAL:    11,867,776\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "10",
      "metadata": {
        "id": "10"
      },
      "outputs": [],
      "source": [
        "transform = DINOTransform()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "11",
      "metadata": {
        "id": "11"
      },
      "outputs": [],
      "source": [
        "# we ignore object detection annotations by setting target_transform to return 0\n",
        "def target_transform(t):\n",
        "    return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "12",
      "metadata": {
        "id": "12"
      },
      "outputs": [],
      "source": [
        "# dataset = torchvision.datasets.VOCDetection(\n",
        "#     \"datasets/pascal_voc\",\n",
        "#     download=True,\n",
        "#     transform=transform,\n",
        "#     target_transform=target_transform,\n",
        "# )\n",
        "\n",
        "# or create a dataset from a folder containing images or videos:\n",
        "# dataset = LightlyDataset(\"path/to/folder\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "13",
      "metadata": {
        "id": "13"
      },
      "outputs": [],
      "source": [
        "dataloader = torch.utils.data.DataLoader(\n",
        "    dataset,\n",
        "    batch_size=128,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    num_workers=8,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "14",
      "metadata": {
        "id": "14"
      },
      "outputs": [],
      "source": [
        "criterion = DINOLoss(\n",
        "    output_dim=2048,\n",
        "    warmup_teacher_temp_epochs=5,\n",
        ")\n",
        "# move loss to correct device because it also contains parameters\n",
        "criterion = criterion.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "15",
      "metadata": {
        "id": "15"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "16",
      "metadata": {
        "id": "16"
      },
      "outputs": [],
      "source": [
        "epochs = 100"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from pathlib import Path\n",
        "import wandb\n",
        "\n",
        "# ---------- Drive setup ----------\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    DRIVE_ROOT = Path(\"/content/drive/MyDrive\")\n",
        "    IS_COLAB = True\n",
        "    print(\"✓ Running on Colab, Drive mounted.\")\n",
        "except Exception:\n",
        "    DRIVE_ROOT = Path(\"./saved_models\")\n",
        "    IS_COLAB = False\n",
        "    print(\"⚠️ Not on Colab, using local folder ./saved_models\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqQ4dQQ4AcC_",
        "outputId": "c79e25a4-4c5d-4b41-98dc-d6663316d91d"
      },
      "id": "OqQ4dQQ4AcC_",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "✓ Running on Colab, Drive mounted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17",
      "metadata": {
        "id": "17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c3ca42c8-834a-414e-b64a-f0048b3f0af6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss/step</td><td>▅████▇▆▆▆▆▆▆▆▄▄▃▃▄▄▄▃▃▃▃▂▁▃▄▂▂▂▃▃▃▂▃▃▂▃▁</td></tr><tr><td>step</td><td>▁▁▁▁▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇███</td></tr><tr><td>time/step_sec</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>loss/step</td><td>3.72751</td></tr><tr><td>step</td><td>465</td></tr><tr><td>time/step_sec</td><td>0.78308</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">dino-run-1</strong> at: <a href='https://wandb.ai/amogh-gulati-new-york-university/dino-v1/runs/wyp084pv' target=\"_blank\">https://wandb.ai/amogh-gulati-new-york-university/dino-v1/runs/wyp084pv</a><br> View project at: <a href='https://wandb.ai/amogh-gulati-new-york-university/dino-v1' target=\"_blank\">https://wandb.ai/amogh-gulati-new-york-university/dino-v1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251129_051334-wyp084pv/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251129_052008-epw8hu29</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/amogh-gulati-new-york-university/dino-v1/runs/epw8hu29' target=\"_blank\">dino-run-1</a></strong> to <a href='https://wandb.ai/amogh-gulati-new-york-university/dino-v1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/amogh-gulati-new-york-university/dino-v1' target=\"_blank\">https://wandb.ai/amogh-gulati-new-york-university/dino-v1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/amogh-gulati-new-york-university/dino-v1/runs/epw8hu29' target=\"_blank\">https://wandb.ai/amogh-gulati-new-york-university/dino-v1/runs/epw8hu29</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100: 100%|██████████| 3906/3906 [50:50<00:00,  1.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 00, loss: 2.86400\n",
            "✓ Saved checkpoint: /content/drive/MyDrive/dino-v1/dino-v1_latest.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/100: 100%|██████████| 3906/3906 [50:47<00:00,  1.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 01, loss: 3.80231\n",
            "✓ Saved checkpoint: /content/drive/MyDrive/dino-v1/dino-v1_latest.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/100: 100%|██████████| 3906/3906 [50:45<00:00,  1.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 02, loss: 2.94557\n",
            "✓ Saved checkpoint: /content/drive/MyDrive/dino-v1/dino-v1_latest.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/100: 100%|██████████| 3906/3906 [50:43<00:00,  1.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 03, loss: 2.58663\n",
            "✓ Saved checkpoint: /content/drive/MyDrive/dino-v1/dino-v1_latest.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/100: 100%|██████████| 3906/3906 [50:43<00:00,  1.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 04, loss: 2.44541\n",
            "✓ Saved checkpoint: /content/drive/MyDrive/dino-v1/dino-v1_latest.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/100: 100%|██████████| 3906/3906 [50:42<00:00,  1.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 05, loss: 2.35560\n",
            "✓ Saved checkpoint: /content/drive/MyDrive/dino-v1/dino-v1_latest.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/100: 100%|██████████| 3906/3906 [50:42<00:00,  1.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 06, loss: 2.29149\n",
            "✓ Saved checkpoint: /content/drive/MyDrive/dino-v1/dino-v1_latest.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/100: 100%|██████████| 3906/3906 [50:40<00:00,  1.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 07, loss: 2.24075\n",
            "✓ Saved checkpoint: /content/drive/MyDrive/dino-v1/dino-v1_latest.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/100: 100%|██████████| 3906/3906 [50:39<00:00,  1.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 08, loss: 2.19772\n",
            "✓ Saved checkpoint: /content/drive/MyDrive/dino-v1/dino-v1_latest.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/100: 100%|██████████| 3906/3906 [50:41<00:00,  1.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 09, loss: 2.15910\n",
            "✓ Saved checkpoint: /content/drive/MyDrive/dino-v1/dino-v1_latest.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/100: 100%|██████████| 3906/3906 [50:41<00:00,  1.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 10, loss: 2.12437\n",
            "✓ Saved checkpoint: /content/drive/MyDrive/dino-v1/dino-v1_latest.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/100: 100%|██████████| 3906/3906 [50:41<00:00,  1.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 11, loss: 2.09420\n",
            "✓ Saved checkpoint: /content/drive/MyDrive/dino-v1/dino-v1_latest.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/100: 100%|██████████| 3906/3906 [50:44<00:00,  1.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 12, loss: 2.06601\n",
            "✓ Saved checkpoint: /content/drive/MyDrive/dino-v1/dino-v1_latest.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/100: 100%|██████████| 3906/3906 [50:41<00:00,  1.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 13, loss: 2.04341\n",
            "✓ Saved checkpoint: /content/drive/MyDrive/dino-v1/dino-v1_latest.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/100: 100%|██████████| 3906/3906 [50:39<00:00,  1.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 14, loss: 2.02369\n",
            "✓ Saved checkpoint: /content/drive/MyDrive/dino-v1/dino-v1_latest.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/100: 100%|██████████| 3906/3906 [50:35<00:00,  1.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 15, loss: 2.00340\n",
            "✓ Saved checkpoint: /content/drive/MyDrive/dino-v1/dino-v1_latest.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/100: 100%|██████████| 3906/3906 [50:35<00:00,  1.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 16, loss: 1.98550\n",
            "✓ Saved checkpoint: /content/drive/MyDrive/dino-v1/dino-v1_latest.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/100: 100%|██████████| 3906/3906 [50:32<00:00,  1.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 17, loss: 1.96837\n",
            "✓ Saved checkpoint: /content/drive/MyDrive/dino-v1/dino-v1_latest.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/100: 100%|██████████| 3906/3906 [50:34<00:00,  1.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 18, loss: 1.95378\n",
            "✓ Saved checkpoint: /content/drive/MyDrive/dino-v1/dino-v1_latest.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/100: 100%|██████████| 3906/3906 [50:36<00:00,  1.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 19, loss: 1.93910\n",
            "✓ Saved checkpoint: /content/drive/MyDrive/dino-v1/dino-v1_latest.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21/100: 100%|██████████| 3906/3906 [50:38<00:00,  1.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 20, loss: 1.92521\n",
            "✓ Saved checkpoint: /content/drive/MyDrive/dino-v1/dino-v1_latest.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22/100: 100%|██████████| 3906/3906 [50:37<00:00,  1.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 21, loss: 1.91157\n",
            "✓ Saved checkpoint: /content/drive/MyDrive/dino-v1/dino-v1_latest.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23/100: 100%|██████████| 3906/3906 [50:40<00:00,  1.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 22, loss: 1.90027\n",
            "✓ Saved checkpoint: /content/drive/MyDrive/dino-v1/dino-v1_latest.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24/100: 100%|██████████| 3906/3906 [50:37<00:00,  1.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 23, loss: 1.88786\n",
            "✓ Saved checkpoint: /content/drive/MyDrive/dino-v1/dino-v1_latest.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25/100: 100%|██████████| 3906/3906 [50:39<00:00,  1.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 24, loss: 1.87855\n",
            "✓ Saved checkpoint: /content/drive/MyDrive/dino-v1/dino-v1_latest.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26/100:  92%|█████████▏| 3597/3906 [46:42<04:01,  1.28it/s]"
          ]
        }
      ],
      "source": [
        "# ---------- wandb init ----------\n",
        "# ---------- Project / save dir ----------\n",
        "PROJECT_NAME = \"dino-v1\"  # wandb project AND folder name\n",
        "save_dir = DRIVE_ROOT / PROJECT_NAME\n",
        "save_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "wandb.init(\n",
        "    entity=\"amogh-gulati-new-york-university\",\n",
        "    project=PROJECT_NAME,\n",
        "    name=\"dino-run-1\",      # change run name if you like\n",
        ")\n",
        "\n",
        "print(\"Starting Training\")\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "global_step = 0\n",
        "step_start = time.time()\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    momentum_val = cosine_schedule(epoch, epochs, 0.996, 1)\n",
        "\n",
        "    for views in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\"):   # views is that list you just inspected\n",
        "        # EMA update for teacher\n",
        "        update_momentum(model.student_backbone, model.teacher_backbone, m=momentum_val)\n",
        "        update_momentum(model.student_head, model.teacher_head, m=momentum_val)\n",
        "\n",
        "        # move all crops to GPU\n",
        "        views = [v.to(device) for v in views]\n",
        "\n",
        "        # first two are global crops for the teacher\n",
        "        global_views = views[:2]\n",
        "\n",
        "        # teacher only on global crops\n",
        "        teacher_out = [model.forward_teacher(v) for v in global_views]\n",
        "\n",
        "        # student on all crops (global + local)\n",
        "        student_out = [model.forward(v) for v in views]\n",
        "\n",
        "        loss = criterion(teacher_out, student_out, epoch=epoch)\n",
        "        total_loss += loss.detach()\n",
        "\n",
        "        loss.backward()\n",
        "        model.student_head.cancel_last_layer_gradients(current_epoch=epoch)\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # ---- wandb STEP LOGGING ----\n",
        "        wandb.log(\n",
        "            {\n",
        "                \"loss/step\": loss.item(),\n",
        "                \"time/step_sec\": time.time() - step_start,\n",
        "                \"step\": global_step,\n",
        "                \"epoch\": epoch,\n",
        "            },\n",
        "            step=global_step,\n",
        "        )\n",
        "\n",
        "        global_step += 1\n",
        "        step_start = time.time()\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    print(f\"epoch: {epoch:>02}, loss: {avg_loss:.5f}\")\n",
        "\n",
        "    # ---- wandb logging ----\n",
        "    wandb.log({\n",
        "        \"loss/train\": avg_loss,\n",
        "        \"epoch\": epoch,\n",
        "    })\n",
        "\n",
        "    # ---- Save checkpoint to Drive (always same filename) ----\n",
        "    ckpt_path = save_dir / f\"{PROJECT_NAME}_latest.pt\"\n",
        "    torch.save(\n",
        "        {\n",
        "            \"epoch\": epoch,\n",
        "            \"model_state\": model.state_dict(),\n",
        "            \"optimizer_state\": optimizer.state_dict(),\n",
        "            \"avg_loss\": avg_loss,\n",
        "        },\n",
        "        ckpt_path,\n",
        "    )\n",
        "    print(f\"✓ Saved checkpoint: {ckpt_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "views = next(iter(dataloader))\n",
        "print(type(views), len(views))\n",
        "for i, v in enumerate(views):\n",
        "    print(i, v.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cu5UWVs_RqX",
        "outputId": "ec407eed-ad7b-4c8c-af37-92ca36690f6c"
      },
      "id": "4cu5UWVs_RqX",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'> 8\n",
            "0 torch.Size([64, 3, 224, 224])\n",
            "1 torch.Size([64, 3, 224, 224])\n",
            "2 torch.Size([64, 3, 96, 96])\n",
            "3 torch.Size([64, 3, 96, 96])\n",
            "4 torch.Size([64, 3, 96, 96])\n",
            "5 torch.Size([64, 3, 96, 96])\n",
            "6 torch.Size([64, 3, 96, 96])\n",
            "7 torch.Size([64, 3, 96, 96])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jKmkTErc_c3S"
      },
      "id": "jKmkTErc_c3S",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9cfd55e334fc4943b4674f3ba8502249": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f5ac001d79c84bc697ca2180371a8587",
              "IPY_MODEL_5cc70c49ab194fb2a3891387b414ae69",
              "IPY_MODEL_4bbed79e5c47409b92cf09d5d440034e"
            ],
            "layout": "IPY_MODEL_18901c5c91c64449ab3a656ca98da3ab"
          }
        },
        "f5ac001d79c84bc697ca2180371a8587": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_953a58a23a7c49a7a196c85d31bfc3de",
            "placeholder": "​",
            "style": "IPY_MODEL_b7784a2864f548a585841176447886c4",
            "value": "Fetching 6 files: 100%"
          }
        },
        "5cc70c49ab194fb2a3891387b414ae69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_048804520ca544ea9580b6e1752033e7",
            "max": 6,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_88a7c0f2334e4b7c859eab2ec0a6b364",
            "value": 6
          }
        },
        "4bbed79e5c47409b92cf09d5d440034e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93c81c0b7064417186bd7dc336b37318",
            "placeholder": "​",
            "style": "IPY_MODEL_866161d5edc9424f8144f6316f49bc47",
            "value": " 6/6 [00:00&lt;00:00, 675.90it/s]"
          }
        },
        "18901c5c91c64449ab3a656ca98da3ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "953a58a23a7c49a7a196c85d31bfc3de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7784a2864f548a585841176447886c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "048804520ca544ea9580b6e1752033e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88a7c0f2334e4b7c859eab2ec0a6b364": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "93c81c0b7064417186bd7dc336b37318": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "866161d5edc9424f8144f6316f49bc47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}