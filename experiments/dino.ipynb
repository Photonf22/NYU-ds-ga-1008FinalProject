{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "id": "5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import copy\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "from lightly.loss import DINOLoss\n",
    "from lightly.models.modules import DINOProjectionHead\n",
    "from lightly.models.utils import deactivate_requires_grad, update_momentum\n",
    "from lightly.transforms.dino_transform import DINOTransform\n",
    "from lightly.utils.scheduler import cosine_schedule\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import glob\n",
    "from huggingface_hub import snapshot_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d9c829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_distributed():\n",
    "    \"\"\"\n",
    "    Initialize torch.distributed if available; return (is_distributed, rank, world_size, device).\n",
    "    \"\"\"\n",
    "    if \"RANK\" in os.environ and \"WORLD_SIZE\" in os.environ:\n",
    "        rank = int(os.environ[\"RANK\"])\n",
    "        world_size = int(os.environ[\"WORLD_SIZE\"])\n",
    "        local_rank = int(os.environ.get(\"LOCAL_RANK\", 0))\n",
    "        dist.init_process_group(backend=\"nccl\")\n",
    "        torch.cuda.set_device(local_rank)\n",
    "        device = torch.device(f\"cuda:{local_rank}\")\n",
    "        is_distributed = True\n",
    "    else:\n",
    "        # Fallback: single GPU / CPU\n",
    "        rank = 0\n",
    "        world_size = 1\n",
    "        is_distributed = False\n",
    "        if torch.cuda.is_available():\n",
    "            device = torch.device(\"cuda:0\")\n",
    "        else:\n",
    "            device = torch.device(\"cpu\")\n",
    "    return is_distributed, rank, world_size, device\n",
    "\n",
    "is_distributed, rank, world_size, device = init_distributed()\n",
    "print(f\"is_distributed={is_distributed}, rank={rank}, world_size={world_size}, device={device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bJWwZr0Q6oLu",
   "metadata": {
    "id": "bJWwZr0Q6oLu"
   },
   "outputs": [],
   "source": [
    "class RawImageDataset(Dataset):\n",
    "    \"\"\"Dataset that loads images directly from raw files.\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, transform=None, image_extensions=None):\n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.transform = transform\n",
    "\n",
    "        if image_extensions is None:\n",
    "            image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.JPEG', '*.JPG', '*.PNG']\n",
    "\n",
    "        # Find all image files\n",
    "        self.image_paths = []\n",
    "        print(f\"Searching for images in: {self.root_dir}\")\n",
    "\n",
    "        for pattern in image_extensions:\n",
    "            found = glob.glob(str(self.root_dir / '**' / pattern), recursive=True)\n",
    "            self.image_paths.extend(found)\n",
    "            if found:\n",
    "                print(f\"  Found {len(found)} {pattern} files\")\n",
    "\n",
    "        self.image_paths.sort()\n",
    "        print(f\"Total images found: {len(self.image_paths)}\")\n",
    "\n",
    "        if len(self.image_paths) == 0:\n",
    "            print(\"\\nWarning: No images found. Directory structure (first 20 items):\")\n",
    "            for item in sorted(self.root_dir.rglob('*'))[:20]:\n",
    "                print(f\"  {item}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # import pdb\n",
    "        # pdb.set_trace()\n",
    "        img_path = self.image_paths[idx]\n",
    "\n",
    "        try:\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {img_path}: {e}\")\n",
    "            img = Image.new('RGB', (96, 96), color='black')\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "            # import pdb; pdb.set_trace()\n",
    "            # print(img.shape,\"old image shape\")\n",
    "            # img = img[0]\n",
    "            # print(img.shape,\"new image shape\")\n",
    "\n",
    "        return img\n",
    "\n",
    "\n",
    "def download_and_extract_dataset(repo_id, cache_dir=None, max_workers=4):\n",
    "    \"\"\"Download and extract dataset from HuggingFace.\"\"\"\n",
    "\n",
    "    print(f\"Downloading dataset from {repo_id}...\")\n",
    "\n",
    "    try:\n",
    "        local_dir = snapshot_download(\n",
    "            repo_id=repo_id,\n",
    "            repo_type=\"dataset\",\n",
    "            cache_dir=cache_dir,\n",
    "            max_workers=max_workers,\n",
    "            resume_download=True,\n",
    "        )\n",
    "        print(f\"Dataset downloaded to: {local_dir}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during download: {e}\")\n",
    "        print(\"Retrying with single worker...\")\n",
    "        local_dir = snapshot_download(\n",
    "            repo_id=repo_id,\n",
    "            repo_type=\"dataset\",\n",
    "            cache_dir=cache_dir,\n",
    "            max_workers=1,\n",
    "            resume_download=True,\n",
    "        )\n",
    "        print(f\"Dataset downloaded to: {local_dir}\")\n",
    "\n",
    "    # Extract zip files if present\n",
    "    local_path = Path(local_dir)\n",
    "    zip_files = list(local_path.glob('*.zip'))\n",
    "\n",
    "    if zip_files:\n",
    "        print(f\"\\nFound {len(zip_files)} zip files. Extracting...\")\n",
    "        extract_dir = local_path / 'extracted'\n",
    "        extract_dir.mkdir(exist_ok=True)\n",
    "\n",
    "        # for zip_file in zip_files:\n",
    "        #     print(f\"  Extracting {zip_file.name}...\")\n",
    "        #     try:\n",
    "        #         with zipfile.ZipFile(zip_file, 'r') as zf:\n",
    "        #             zf.extractall(extract_dir)\n",
    "        #         print(\"    ✓ Extracted successfully\")\n",
    "        #     except Exception as e:\n",
    "        #         print(f\"    ✗ Error: {e}\")\n",
    "\n",
    "        return extract_dir\n",
    "    else:\n",
    "        print(\"No zip files found, using directory as-is\")\n",
    "        return local_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cd3397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "data_dir = Path(\"./data/devel\")\n",
    "transform = DINOTransform()\n",
    "dataset = RawImageDataset(data_dir, transform=transform)\n",
    "print(f\"\\nDataset ready with {len(dataset)} images\")\n",
    "\n",
    "# Per-GPU batch size (global batch = per_gpu_batch * world_size)\n",
    "per_gpu_batch_size = 128  # adjust as needed\n",
    "\n",
    "if is_distributed:\n",
    "    train_sampler = DistributedSampler(\n",
    "        dataset,\n",
    "        num_replicas=world_size,\n",
    "        rank=rank,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    shuffle = False  # sampler handles shuffling\n",
    "else:\n",
    "    train_sampler = None\n",
    "    shuffle = True\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=per_gpu_batch_size,\n",
    "    sampler=train_sampler,\n",
    "    shuffle=shuffle,\n",
    "    drop_last=True,\n",
    "    num_workers=8,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "id": "6"
   },
   "outputs": [],
   "source": [
    "resnet = torchvision.models.resnet34()\n",
    "backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
    "input_dim = 512\n",
    "\n",
    "class DINO(torch.nn.Module):\n",
    "    def __init__(self, backbone, input_dim):\n",
    "        super().__init__()\n",
    "        self.student_backbone = backbone\n",
    "        self.student_head = DINOProjectionHead(\n",
    "            input_dim, 512, 64, 2048, freeze_last_layer=30\n",
    "        )\n",
    "        self.teacher_backbone = copy.deepcopy(backbone)\n",
    "        self.teacher_head = DINOProjectionHead(input_dim, 512, 64, 2048)\n",
    "        deactivate_requires_grad(self.teacher_backbone)\n",
    "        deactivate_requires_grad(self.teacher_head)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.student_backbone(x).flatten(start_dim=1)\n",
    "        z = self.student_head(y)\n",
    "        return z\n",
    "\n",
    "    def forward_teacher(self, x):\n",
    "        y = self.teacher_backbone(x).flatten(start_dim=1)\n",
    "        z = self.teacher_head(y)\n",
    "        return z\n",
    "\n",
    "base_model = DINO(backbone, input_dim).to(device)\n",
    "if is_distributed:\n",
    "    model = DDP(base_model, device_ids=[device.index], output_device=device.index)\n",
    "else:\n",
    "    model = base_model\n",
    "\n",
    "criterion = DINOLoss(\n",
    "    output_dim=2048,\n",
    "    warmup_teacher_temp=0.08,\n",
    "    teacher_temp=0.04,\n",
    "    warmup_teacher_temp_epochs=10,\n",
    "    student_temp=0.1,\n",
    "    center_momentum=0.9,\n",
    ").to(device)\n",
    "\n",
    "global_batch_size = per_gpu_batch_size * world_size\n",
    "base_lr0 = 5e-4\n",
    "base_lr = base_lr0 * (global_batch_size / 256)\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=3e-4,  \n",
    "    weight_decay=1e-4,\n",
    "    betas=(0.9, 0.95),\n",
    ")\n",
    "\n",
    "warmup_epochs = 10\n",
    "min_lr = 1e-6\n",
    "epochs = 250\n",
    "\n",
    "def cosine_lr(epoch):\n",
    "    if epoch < warmup_epochs:\n",
    "        return (epoch + 1) / warmup_epochs\n",
    "    t = (epoch - warmup_epochs) / max(1, (epochs - warmup_epochs))\n",
    "    return min_lr / base_lr + 0.5 * (1 + math.cos(math.pi * t)) * (1 - min_lr / base_lr)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, cosine_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HS3dE7eSDZMn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HS3dE7eSDZMn",
    "outputId": "d6f71511-7cdc-400a-abc9-88cdd6e40624"
   },
   "outputs": [],
   "source": [
    "def count_params(module):\n",
    "    return sum(p.numel() for p in module.parameters())\n",
    "\n",
    "total_params = count_params(model)\n",
    "student_backbone_params = count_params(model.student_backbone)\n",
    "student_head_params = count_params(model.student_head)\n",
    "teacher_backbone_params = count_params(model.teacher_backbone)\n",
    "teacher_head_params = count_params(model.teacher_head)\n",
    "\n",
    "student_total = student_backbone_params + student_head_params\n",
    "teacher_total = teacher_backbone_params + teacher_head_params\n",
    "\n",
    "print(f\"Total params (student + teacher + heads): {total_params:,}\")\n",
    "print(f\"  Student backbone: {student_backbone_params:,}\")\n",
    "print(f\"  Student head:     {student_head_params:,}\")\n",
    "print(f\"  Student TOTAL:    {student_total:,}\")\n",
    "print(f\"  Teacher backbone: {teacher_backbone_params:,}\")\n",
    "print(f\"  Teacher head:     {teacher_head_params:,}\")\n",
    "print(f\"  Teacher TOTAL:    {teacher_total:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "id": "10"
   },
   "outputs": [],
   "source": [
    "transform = DINOTransform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "id": "11"
   },
   "outputs": [],
   "source": [
    "# we ignore object detection annotations by setting target_transform to return 0\n",
    "def target_transform(t):\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7bc79c-c04b-4491-9aca-b0efa6c2233d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def teacher_entropy(logits):\n",
    "    # logits: (B, C)\n",
    "    probs = torch.softmax(logits, dim=-1)\n",
    "    return -(probs * (probs + 1e-8).log()).sum(dim=-1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "id": "16"
   },
   "outputs": [],
   "source": [
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OqQ4dQQ4AcC_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OqQ4dQQ4AcC_",
    "outputId": "c79e25a4-4c5d-4b41-98dc-d6663316d91d"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "import wandb\n",
    "\n",
    "# ---------- Drive setup ----------\n",
    "# try:\n",
    "#     from google.colab import drive\n",
    "#     drive.mount('/content/drive')\n",
    "#     DRIVE_ROOT = Path(\"/content/drive/MyDrive\")\n",
    "#     IS_COLAB = True\n",
    "#     print(\"✓ Running on Colab, Drive mounted.\")\n",
    "# except Exception:\n",
    "#     DRIVE_ROOT = Path(\"./saved_models\")\n",
    "#     IS_COLAB = False\n",
    "#     print(\"⚠️ Not on Colab, using local folder ./saved_models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "17",
    "outputId": "c3ca42c8-834a-414e-b64a-f0048b3f0af6"
   },
   "outputs": [],
   "source": [
    "# ---------- wandb init ----------\n",
    "# ---------- Project / save dir ----------\n",
    "PROJECT_NAME = \"dino-v1\"  # wandb project AND folder name\n",
    "DRIVE_ROOT = \"outputs\"\n",
    "save_dir = Path(DRIVE_ROOT) / Path(PROJECT_NAME)\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "wandb.init(\n",
    "    entity=\"lquan9\",\n",
    "    project=PROJECT_NAME,\n",
    "    name=\"dino-resnet34-run\",\n",
    ")\n",
    "\n",
    "print(\"Starting Training\")\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "global_step = 0\n",
    "step_start = time.time()\n",
    "for epoch in range(epochs):\n",
    "    if is_distributed:\n",
    "        dataloader.sampler.set_epoch(epoch)\n",
    "    \n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    momentum_val = cosine_schedule(epoch, epochs, 0.996, 1)\n",
    "\n",
    "    for views in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\"):   # views is that list you just inspected\n",
    "        raw_model = model.module if isinstance(model, DDP) else model\n",
    "        # EMA update for teacher\n",
    "        update_momentum(raw_model.student_backbone, raw_model.teacher_backbone, m=momentum_val)\n",
    "        update_momentum(raw_model.student_head, raw_model.teacher_head, m=momentum_val)\n",
    "\n",
    "        # move all crops to GPU\n",
    "        views = [v.to(device, non_blocking=True) for v in views]\n",
    "\n",
    "        # first two are global crops for the teacher\n",
    "        global_views = views[:2]\n",
    "\n",
    "        # teacher only on global crops\n",
    "        teacher_out = [raw_model.forward_teacher(v) for v in global_views]\n",
    "\n",
    "        # Inside training loop, after computing teacher_out\n",
    "        with torch.no_grad():\n",
    "        # teacher_out is a list of tensors for the two global crops, same shape\n",
    "            t_logits = teacher_out[0]  # (B, 2048)\n",
    "            ent = teacher_entropy(t_logits)\n",
    "            if global_step % 100 == 0:\n",
    "                wandb.log({\"teacher_entropy\": ent.item(), \"step\": global_step})\n",
    "\n",
    "        # student on all crops (global + local)\n",
    "        student_out = [raw_model.forward(v) for v in views]\n",
    "\n",
    "        loss = criterion(teacher_out, student_out, epoch=epoch)\n",
    "\n",
    "        if is_distributed:\n",
    "            loss_reduced = loss.detach().clone()\n",
    "            dist.all_reduce(loss_reduced, op=dist.ReduceOp.SUM)\n",
    "            loss_reduced = loss_reduced / world_size\n",
    "        else:\n",
    "            loss_reduced = loss.detach()\n",
    "\n",
    "        total_loss += loss_reduced\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # freeze_epochs = 30  # instead of relying on default 1 epoch\n",
    "        \n",
    "        raw_model.student_head.cancel_last_layer_gradients(current_epoch=epoch)\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        # ---- wandb STEP LOGGING ----\n",
    "        if rank == 0:\n",
    "            wandb.log(\n",
    "                {\n",
    "                    \"loss/step\": loss.item(),\n",
    "                    \"time/step_sec\": time.time() - step_start,\n",
    "                    \"step\": global_step,\n",
    "                    \"epoch\": epoch,\n",
    "                },\n",
    "                step=global_step,\n",
    "            )\n",
    "\n",
    "        global_step += 1\n",
    "        step_start = time.time()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    if rank == 0:\n",
    "        print(f\"epoch: {epoch:>02}, loss: {avg_loss:.5f}\")\n",
    "\n",
    "        # ---- wandb logging ----\n",
    "        wandb.log({\n",
    "            \"loss/train\": avg_loss,\n",
    "            \"epoch\": epoch,\n",
    "        })\n",
    "\n",
    "        # ---- Save checkpoint to Drive (always same filename) ----\n",
    "        ckpt_path = save_dir / f\"{PROJECT_NAME}_latest.pt\"\n",
    "        torch.save(\n",
    "            {\n",
    "                \"epoch\": epoch,\n",
    "                \"model_state\": model.state_dict(),\n",
    "                \"optimizer_state\": optimizer.state_dict(),\n",
    "                \"avg_loss\": avg_loss,\n",
    "            },\n",
    "            ckpt_path,\n",
    "        )\n",
    "        print(f\"✓ Saved checkpoint: {ckpt_path}\")\n",
    "\n",
    "if is_distributed:\n",
    "    dist.destroy_process_group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cu5UWVs_RqX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4cu5UWVs_RqX",
    "outputId": "ec407eed-ad7b-4c8c-af37-92ca36690f6c"
   },
   "outputs": [],
   "source": [
    "views = next(iter(dataloader))\n",
    "print(type(views), len(views))\n",
    "for i, v in enumerate(views):\n",
    "    print(i, v.shape)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "048804520ca544ea9580b6e1752033e7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "18901c5c91c64449ab3a656ca98da3ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4bbed79e5c47409b92cf09d5d440034e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_93c81c0b7064417186bd7dc336b37318",
      "placeholder": "​",
      "style": "IPY_MODEL_866161d5edc9424f8144f6316f49bc47",
      "value": " 6/6 [00:00&lt;00:00, 675.90it/s]"
     }
    },
    "5cc70c49ab194fb2a3891387b414ae69": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_048804520ca544ea9580b6e1752033e7",
      "max": 6,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_88a7c0f2334e4b7c859eab2ec0a6b364",
      "value": 6
     }
    },
    "866161d5edc9424f8144f6316f49bc47": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "88a7c0f2334e4b7c859eab2ec0a6b364": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "93c81c0b7064417186bd7dc336b37318": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "953a58a23a7c49a7a196c85d31bfc3de": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9cfd55e334fc4943b4674f3ba8502249": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f5ac001d79c84bc697ca2180371a8587",
       "IPY_MODEL_5cc70c49ab194fb2a3891387b414ae69",
       "IPY_MODEL_4bbed79e5c47409b92cf09d5d440034e"
      ],
      "layout": "IPY_MODEL_18901c5c91c64449ab3a656ca98da3ab"
     }
    },
    "b7784a2864f548a585841176447886c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f5ac001d79c84bc697ca2180371a8587": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_953a58a23a7c49a7a196c85d31bfc3de",
      "placeholder": "​",
      "style": "IPY_MODEL_b7784a2864f548a585841176447886c4",
      "value": "Fetching 6 files: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
