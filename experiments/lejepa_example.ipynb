{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0de1e94b",
   "metadata": {},
   "source": [
    "### LeJEPA: Minimal Example\n",
    "[Github](https://github.com/rbalestr-lab/lejepa/blob/main/MINIMAL.md), [Paper](https://arxiv.org/abs/2511.08544)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6904bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e2cebe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import v2\n",
    "import timm, wandb, hydra, tqdm\n",
    "from omegaconf import DictConfig\n",
    "from datasets import load_dataset\n",
    "from torch.amp import GradScaler, autocast\n",
    "from torch.optim.lr_scheduler import LinearLR, CosineAnnealingLR, SequentialLR\n",
    "from torchvision.ops import MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c20b24",
   "metadata": {},
   "source": [
    "Let's define our backbone with projector, our dataset, and our infamous SIGReg objective \n",
    "(the core component of LeJEPA). One may notice a small difference in the implementation of SIGReg from the paper's one: \n",
    "we leverage the symmetric property of the ECF/CF improve the quadrature efficient \n",
    "(integrate on [0, t_max] and doubling, instead of integrating on [-t_max, t_max]), improved quadrature for free:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42800fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SIGReg(torch.nn.Module):\n",
    "    def __init__(self, knots=17):\n",
    "        super().__init__()\n",
    "        t = torch.linspace(0, 3, knots, dtype=torch.float32)\n",
    "        dt = 3 / (knots - 1)\n",
    "        weights = torch.full((knots,), 2 * dt, dtype=torch.float32)\n",
    "        weights[[0, -1]] = dt\n",
    "        window = torch.exp(-t.square() / 2.0)\n",
    "        self.register_buffer(\"t\", t)\n",
    "        self.register_buffer(\"phi\", window)\n",
    "        self.register_buffer(\"weights\", weights * window)\n",
    "\n",
    "    def forward(self, proj):\n",
    "        A = torch.randn(proj.size(-1), 256, device=\"cuda\")\n",
    "        A = A.div_(A.norm(p=2, dim=0))\n",
    "        x_t = (proj @ A).unsqueeze(-1) * self.t\n",
    "        err = (x_t.cos().mean(-3) - self.phi).square() + x_t.sin().mean(-3).square()\n",
    "        statistic = (err @ self.weights) * proj.size(-2)\n",
    "        return statistic.mean()\n",
    "\n",
    "\n",
    "class ViTEncoder(nn.Module):\n",
    "    def __init__(self, proj_dim=128):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model(\n",
    "            \"vit_small_patch8_224\",\n",
    "            pretrained=False,\n",
    "            num_classes=512,\n",
    "            drop_path_rate=0.1,\n",
    "            img_size=128,\n",
    "        )\n",
    "        self.proj = MLP(512, [2048, 2048, proj_dim], norm_layer=nn.BatchNorm1d)\n",
    "\n",
    "    def forward(self, x):\n",
    "        N, V = x.shape[:2]\n",
    "        emb = self.backbone(x.flatten(0, 1))\n",
    "        return emb, self.proj(emb).reshape(N, V, -1).transpose(0, 1)\n",
    "\n",
    "\n",
    "class HFDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, split, V=1):\n",
    "        self.V = V\n",
    "        self.ds = load_dataset(\"frgfm/imagenette\", \"160px\", split=split)\n",
    "        self.aug = v2.Compose(\n",
    "            [\n",
    "                v2.RandomResizedCrop(128, scale=(0.08, 1.0)),\n",
    "                v2.RandomApply([v2.ColorJitter(0.8, 0.8, 0.8, 0.2)], p=0.8),\n",
    "                v2.RandomGrayscale(p=0.2),\n",
    "                v2.RandomApply([v2.GaussianBlur(kernel_size=7, sigma=(0.1, 2.0))]),\n",
    "                v2.RandomApply([v2.RandomSolarize(threshold=128)], p=0.2),\n",
    "                v2.RandomHorizontalFlip(),\n",
    "                v2.ToImage(),\n",
    "                v2.ToDtype(torch.float32, scale=True),\n",
    "                v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ]\n",
    "        )\n",
    "        self.test = v2.Compose(\n",
    "            [\n",
    "                v2.Resize(128),\n",
    "                v2.CenterCrop(128),\n",
    "                v2.ToImage(),\n",
    "                v2.ToDtype(torch.float32, scale=True),\n",
    "                v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        item = self.ds[i]\n",
    "        img = item[\"image\"].convert(\"RGB\")\n",
    "        transform = self.aug if self.V > 1 else self.test\n",
    "        return torch.stack([transform(img) for _ in range(self.V)]), item[\"label\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7336f098",
   "metadata": {},
   "source": [
    "And that's all we need to define before creating our main function that will assemble all those components and iterate through training and validation steps! Note that we put some generic hyper-parameters in the above that will not impact performance, e.g., drop_path_rate. Here is the main loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2b12d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @hydra.main(version_base=None)\n",
    "def main(cfg: DictConfig):\n",
    "    wandb.init(project=\"LeJEPA\", config=dict(cfg))\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    train_ds = HFDataset(\"train\", V=cfg.V)\n",
    "    test_ds = HFDataset(\"validation\", V=1)\n",
    "    train = DataLoader(\n",
    "        train_ds, batch_size=cfg.bs, shuffle=True, drop_last=True, num_workers=8\n",
    "    )\n",
    "    test = DataLoader(test_ds, batch_size=256, num_workers=8)\n",
    "\n",
    "    # modules and loss\n",
    "    net = ViTEncoder(proj_dim=cfg.proj_dim).to(\"cuda\")\n",
    "    probe = nn.Sequential(nn.LayerNorm(512), nn.Linear(512, 100)).to(\"cuda\")\n",
    "    sigreg = SIGReg().to(\"cuda\")\n",
    "    # Optimizer and scheduler\n",
    "    g1 = {\"params\": net.parameters(), \"lr\": cfg.lr, \"weight_decay\": 5e-2}\n",
    "    g2 = {\"params\": probe.parameters(), \"lr\": 1e-3, \"weight_decay\": 1e-7}\n",
    "    opt = torch.optim.AdamW([g1, g2])\n",
    "    warmup_steps = len(train)\n",
    "    total_steps = len(train) * cfg.epochs\n",
    "    s1 = LinearLR(opt, start_factor=0.01, total_iters=warmup_steps)\n",
    "    s2 = CosineAnnealingLR(opt, T_max=total_steps - warmup_steps, eta_min=1e-3)\n",
    "    scheduler = SequentialLR(opt, schedulers=[s1, s2], milestones=[warmup_steps])\n",
    "\n",
    "    scaler = GradScaler(enabled=\"cuda\" == \"cuda\")\n",
    "    # Training\n",
    "    for epoch in range(cfg.epochs):\n",
    "        net.train(), probe.train()\n",
    "        for vs, y in tqdm.tqdm(train, total=len(train)):\n",
    "            with autocast(\"cuda\", dtype=torch.bfloat16):\n",
    "                vs = vs.to(\"cuda\", non_blocking=True)\n",
    "                y = y.to(\"cuda\", non_blocking=True)\n",
    "                emb, proj = net(vs)\n",
    "                inv_loss = (proj.mean(0) - proj).square().mean()\n",
    "                sigreg_loss = sigreg(proj)\n",
    "                lejepa_loss = sigreg_loss * cfg.lamb + inv_loss * (1 - cfg.lamb)\n",
    "                y_rep, yhat = y.repeat_interleave(cfg.V), probe(emb.detach())\n",
    "                probe_loss = F.cross_entropy(yhat, y_rep)\n",
    "                loss = lejepa_loss + probe_loss\n",
    "\n",
    "            opt.zero_grad()\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(opt)\n",
    "            scaler.update()\n",
    "            scheduler.step()\n",
    "            wandb.log(\n",
    "                {\n",
    "                    \"train/probe\": probe_loss.item(),\n",
    "                    \"train/lejepa\": lejepa_loss.item(),\n",
    "                    \"train/sigreg\": sigreg_loss.item(),\n",
    "                    \"train/inv\": sigreg_loss.item(),\n",
    "                }\n",
    "            )\n",
    "\n",
    "        # Evaluation\n",
    "        net.eval(), probe.eval()\n",
    "        correct = 0\n",
    "        with torch.inference_mode():\n",
    "            for vs, y in test:\n",
    "                vs = vs.to(\"cuda\", non_blocking=True)\n",
    "                y = y.to(\"cuda\", non_blocking=True)\n",
    "                with autocast(\"cuda\", dtype=torch.bfloat16):\n",
    "                    correct += (probe(net(vs)[0]).argmax(1) == y).sum().item()\n",
    "        wandb.log({\"test/acc\": correct / len(test_ds), \"test/epoch\": epoch})\n",
    "    wandb.finish()\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8c2aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "cfg = OmegaConf.create({\n",
    "    \"V\": 2,\n",
    "    \"bs\": 64,\n",
    "    \"proj_dim\": 128,\n",
    "    \"lr\": 1e-3,\n",
    "    \"epochs\": 10,\n",
    "    \"lamb\": 0.5,\n",
    "})\n",
    "\n",
    "main(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3389918",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ijepa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
